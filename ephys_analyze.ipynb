{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy \n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyQt6.QtCore\n",
    "os.environ[\"QT_API\"] = \"pyqt6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_movie = scipy.io.loadmat('data/Caos_session1/rasters_movies.mat')['rasters']\n",
    "raster_image = scipy.io.loadmat('data/Caos_session1/rasters_images.mat')['rasters_images']\n",
    "\n",
    "movie_names = scipy.io.loadmat('data/Caos_session1/movie_names.mat')['imgs']\n",
    "movie_names = np.asarray([movie_names[i][0][0] for i in range(len(movie_names))])\n",
    "img_names = scipy.io.loadmat('data/Caos_session1/image_names.mat')['imgs_ims']\n",
    "img_names = np.asarray([img_names[i][0][0] for i in range(len(img_names))])\n",
    "\n",
    "spikeID_movie = np.squeeze(scipy.io.loadmat('data/Caos_session1/spikeID_movies.mat')['spike_movies'])\n",
    "spikeID_ims = np.squeeze(scipy.io.loadmat('data/Caos_session1/spikeID_ims.mat')['spike_ims'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  3,  3,  4,  4,  5,  6,  7,  7,  8,  8,  9,  9,  9,  9,\n",
       "       10, 11, 12, 12, 12, 13, 14, 15, 16, 16, 17, 17, 18, 19, 20, 21, 22,\n",
       "       23, 24, 25, 25, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 36,\n",
       "       37, 38, 39, 40, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 51,\n",
       "       52, 53, 54, 55, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 68, 69, 70, 71, 71, 71, 72, 73, 73, 74, 75, 76, 77, 78, 79, 79,\n",
       "       80, 81, 81, 82, 83, 84, 85, 85, 86, 87, 88, 89, 90, 90, 91, 91, 92,\n",
       "       92, 93, 93, 93, 94, 95, 96, 96], dtype=uint8)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikeID_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_channels(spikeID):\n",
    "\n",
    "    channels =[]\n",
    "    currunit = 1\n",
    "\n",
    "    for i in range(len(spikeID)):\n",
    "        if i ==0:\n",
    "            currunit = 1\n",
    "        else:\n",
    "            if spikeID[i-1] == spikeID[i]:\n",
    "                currunit+=1 \n",
    "            else:\n",
    "                currunit = 1\n",
    "\n",
    "        channels.append(f\"Channel{spikeID[i]}_Unit{currunit}\")\n",
    "    return channels\n",
    "\n",
    "channels_movie = convert_channels(spikeID_movie)\n",
    "channels_img = convert_channels(spikeID_ims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze rasters and PSTH averaged over all trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_avg_movie = np.mean(raster_movie, axis=2)\n",
    "trial_avg_image = np.mean(raster_image, axis=2)\n",
    "\n",
    "norm_trial_avg_movie = scipy.stats.zscore(trial_avg_movie, axis=1)\n",
    "norm_trial_avg_image = scipy.stats.zscore(trial_avg_image, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt \n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.imshow(norm_trial_avg_movie)\n",
    "plt.xlabel('Normalized trial averaged activity')\n",
    "plt.ylabel('Channel')\n",
    "plt.colorbar()  # Add a colorbar\n",
    "plt.title('Caos, session1, movies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt \n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.imshow(norm_trial_avg_image)\n",
    "plt.xlabel('Normalized trial averaged activity')\n",
    "plt.ylabel('Channel')\n",
    "plt.colorbar()  # Add a colorbar\n",
    "plt.title('Caos, session1, images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "qual = input()\n",
    "\n",
    "if int(qual) not in [1,2,3,4]:\n",
    "    print('false')\n",
    "else:\n",
    "    print('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def check_PSTH(raster, channels, filename):\n",
    "    qual_dict = {'Poor':[], 'Fair':[], 'Good':[], 'Excellent':[]}\n",
    "    \n",
    "    trial_avg_data = np.mean(raster, axis=2)\n",
    "    sem = scipy.stats.sem(raster, axis=2)\n",
    "\n",
    "    for i in range(trial_avg_data.shape[0]):\n",
    "        fig = plt.figure()\n",
    "        plt.plot(np.arange(trial_avg_data.shape[1]),trial_avg_data[i])\n",
    "        plt.fill_between(np.arange(trial_avg_data.shape[1]),trial_avg_data[i]+1.96*sem[i], trial_avg_data[i]-1.96*sem[i], alpha=0.5)\n",
    "        plt.show()\n",
    "\n",
    "        qual = input(\"How good is this PSTH\")\n",
    "\n",
    "        while qual not in ['1','2','3','4']:\n",
    "            qual = input('invalid input, should be one of 1, 2, 3, 4')\n",
    "            \n",
    "        if qual == '1':\n",
    "            qual_dict['Poor'].append((i, channels[i]))\n",
    "\n",
    "        elif qual == '2':\n",
    "            qual_dict['Fair'].append((i, channels[i]))\n",
    "\n",
    "        elif qual == '3':\n",
    "            qual_dict['Good'].append((i, channels[i]))\n",
    "\n",
    "        elif qual == '4': \n",
    "            qual_dict['Excellent'].append((i, channels[i]))\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "    with open(f'{filename}.pickle', 'wb') as pick:\n",
    "        pickle.dump(qual_dict, pick, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return qual_dict\n",
    "\n",
    "movie_qualdict = check_PSTH(raster_movie, channels_movie, 'data/Caos_session1/movie_PSTH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_qualdict = check_PSTH(raster_image, channels_img, 'data/Caos_session1/image_PSTH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Caos_session1/movie_PSTH.pickle', 'rb') as pick:\n",
    "    movie_qualdict = pickle.load(pick)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_avg_data = np.mean(raster_movie, axis=2)\n",
    "sem = scipy.stats.sem(raster_movie, axis=2)\n",
    "\n",
    "for value in movie_qualdict['Poor']:\n",
    "    fig, plt.figure()\n",
    "\n",
    "    i = value[0]\n",
    "\n",
    "    plt.plot(np.arange(trial_avg_data.shape[1]),trial_avg_data[i])\n",
    "    plt.fill_between(np.arange(trial_avg_data.shape[1]),trial_avg_data[i]+1.96*sem[i], trial_avg_data[i]-1.96*sem[i], alpha=0.5)\n",
    "\n",
    "    #plt.plot(trial_avg_movie[value[0]])\n",
    "    plt.title(f'{value[1]} , poor quality')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "18\n",
      "31\n",
      "55\n",
      "29\n",
      "14\n",
      "17\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "print(len(movie_qualdict['Poor']))\n",
    "print(len(movie_qualdict['Fair']))\n",
    "print(len(movie_qualdict['Good']))\n",
    "print(len(movie_qualdict['Excellent']))\n",
    "\n",
    "print(len(image_qualdict['Poor']))\n",
    "print(len(image_qualdict['Fair']))\n",
    "print(len(image_qualdict['Good']))\n",
    "print(len(image_qualdict['Excellent']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_avg_data = np.mean(raster_movie, axis=2)\n",
    "sem = scipy.stats.sem(raster_movie, axis=2)\n",
    "\n",
    "for value in movie_qualdict['Excellent']:\n",
    "    fig, plt.figure()\n",
    "\n",
    "    i = value[0]\n",
    "\n",
    "    plt.plot(np.arange(trial_avg_data.shape[1]),trial_avg_data[i])\n",
    "    plt.fill_between(np.arange(trial_avg_data.shape[1]),trial_avg_data[i]+1.96*sem[i], trial_avg_data[i]-1.96*sem[i], alpha=0.5)\n",
    "\n",
    "    #plt.plot(trial_avg_movie[value[0]])\n",
    "    plt.title(f'{value[1]} , Excellent quality')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8, 'Channel6_Unit1'), (10, 'Channel7_Unit2'), (22, 'Channel13_Unit1'), (24, 'Channel15_Unit1'), (26, 'Channel16_Unit2'), (41, 'Channel28_Unit1'), (46, 'Channel33_Unit1'), (47, 'Channel34_Unit1'), (48, 'Channel35_Unit1'), (49, 'Channel36_Unit1'), (51, 'Channel37_Unit1'), (52, 'Channel38_Unit1'), (53, 'Channel39_Unit1'), (54, 'Channel40_Unit1'), (56, 'Channel41_Unit1'), (57, 'Channel42_Unit1'), (58, 'Channel43_Unit1'), (59, 'Channel44_Unit1'), (60, 'Channel45_Unit1'), (61, 'Channel46_Unit1'), (62, 'Channel47_Unit1'), (63, 'Channel48_Unit1'), (64, 'Channel49_Unit1'), (65, 'Channel50_Unit1'), (66, 'Channel51_Unit1'), (67, 'Channel51_Unit2'), (68, 'Channel52_Unit1'), (69, 'Channel53_Unit1'), (70, 'Channel54_Unit1'), (72, 'Channel55_Unit2'), (73, 'Channel56_Unit1'), (74, 'Channel57_Unit1'), (76, 'Channel59_Unit1'), (77, 'Channel60_Unit1'), (78, 'Channel61_Unit1'), (79, 'Channel62_Unit1'), (80, 'Channel63_Unit1'), (81, 'Channel64_Unit1'), (82, 'Channel65_Unit1'), (83, 'Channel66_Unit1'), (84, 'Channel67_Unit1'), (85, 'Channel68_Unit1'), (86, 'Channel68_Unit2'), (87, 'Channel69_Unit1'), (90, 'Channel71_Unit2'), (91, 'Channel71_Unit3'), (92, 'Channel72_Unit1'), (93, 'Channel73_Unit1'), (98, 'Channel77_Unit1'), (100, 'Channel79_Unit1'), (104, 'Channel81_Unit2'), (106, 'Channel83_Unit1'), (110, 'Channel86_Unit1'), (118, 'Channel92_Unit1'), (123, 'Channel94_Unit1')]\n",
      "[(0, 'Channel1_Unit1'), (9, 'Channel7_Unit1'), (19, 'Channel12_Unit2'), (23, 'Channel15_Unit1'), (31, 'Channel21_Unit1'), (34, 'Channel24_Unit1'), (40, 'Channel28_Unit1'), (42, 'Channel30_Unit1'), (45, 'Channel33_Unit1'), (46, 'Channel34_Unit1'), (47, 'Channel35_Unit1'), (48, 'Channel36_Unit1'), (50, 'Channel37_Unit1'), (51, 'Channel38_Unit1'), (53, 'Channel39_Unit2'), (54, 'Channel40_Unit1'), (56, 'Channel41_Unit1'), (57, 'Channel42_Unit1'), (58, 'Channel43_Unit1'), (59, 'Channel44_Unit1'), (60, 'Channel45_Unit1'), (61, 'Channel46_Unit1'), (62, 'Channel47_Unit1'), (63, 'Channel48_Unit1'), (64, 'Channel49_Unit1'), (65, 'Channel50_Unit1'), (66, 'Channel51_Unit1'), (68, 'Channel52_Unit1'), (69, 'Channel53_Unit1'), (70, 'Channel54_Unit1'), (72, 'Channel55_Unit2'), (73, 'Channel56_Unit1'), (74, 'Channel57_Unit1'), (75, 'Channel58_Unit1'), (76, 'Channel59_Unit1'), (77, 'Channel60_Unit1'), (78, 'Channel61_Unit1'), (79, 'Channel62_Unit1'), (80, 'Channel63_Unit1'), (81, 'Channel64_Unit1'), (82, 'Channel65_Unit1'), (84, 'Channel67_Unit1'), (85, 'Channel68_Unit1'), (86, 'Channel68_Unit2'), (87, 'Channel69_Unit1'), (90, 'Channel71_Unit2'), (92, 'Channel73_Unit1'), (95, 'Channel75_Unit1'), (97, 'Channel77_Unit1'), (98, 'Channel78_Unit1'), (99, 'Channel79_Unit1'), (100, 'Channel79_Unit2'), (102, 'Channel81_Unit1'), (103, 'Channel81_Unit2'), (105, 'Channel83_Unit1'), (109, 'Channel86_Unit1'), (111, 'Channel88_Unit1'), (112, 'Channel89_Unit1'), (113, 'Channel90_Unit1'), (115, 'Channel91_Unit1'), (117, 'Channel92_Unit1'), (120, 'Channel93_Unit2'), (121, 'Channel93_Unit3'), (122, 'Channel94_Unit1'), (123, 'Channel95_Unit1'), (124, 'Channel96_Unit1')]\n"
     ]
    }
   ],
   "source": [
    "print(movie_qualdict['Excellent'])\n",
    "print(image_qualdict['Excellent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_solid = [channel[1] for channel in movie_qualdict['Excellent']+movie_qualdict['Good']] \n",
    "movie_solid_ind = [channel[0] for channel in movie_qualdict['Excellent']+movie_qualdict['Good']] \n",
    "image_solid = [channel[1] for channel in image_qualdict['Excellent']+image_qualdict['Good']] \n",
    "image_solid_ind = [channel[0] for channel in image_qualdict['Excellent']+image_qualdict['Good']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_solid_chans = [movie_solid_ind[i] for i in range(len(movie_solid)) if movie_solid[i] in image_solid]\n",
    "mov_solid_channames = [movie_solid[i] for i in range(len(movie_solid)) if movie_solid[i] in image_solid]\n",
    "img_solid_chans = [image_solid_ind[i] for i in range(len(image_solid)) if image_solid[i] in movie_solid]\n",
    "img_solid_channames = [image_solid[i] for i in range(len(image_solid)) if image_solid[i] in movie_solid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_sol_chan_sort = sorted(zip(mov_solid_channames, mov_solid_chans), key=lambda x: x[0])\n",
    "img_sol_chan_sort = sorted(zip(img_solid_channames, img_solid_chans), key=lambda x: x[0])\n",
    "\n",
    "sort_mov_channames, sort_mov_indexes = zip(*mov_sol_chan_sort)\n",
    "sort_img_channames, sort_img_indexes = zip(*img_sol_chan_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "print(len(sort_mov_channames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Channel10_Unit1', 'Channel11_Unit1', 'Channel12_Unit2', 'Channel15_Unit1', 'Channel16_Unit2', 'Channel18_Unit1', 'Channel1_Unit1', 'Channel21_Unit1', 'Channel23_Unit1', 'Channel24_Unit1', 'Channel28_Unit1', 'Channel30_Unit1', 'Channel33_Unit1', 'Channel34_Unit1', 'Channel35_Unit1', 'Channel36_Unit1', 'Channel37_Unit1', 'Channel38_Unit1', 'Channel40_Unit1', 'Channel41_Unit1', 'Channel42_Unit1', 'Channel43_Unit1', 'Channel44_Unit1', 'Channel45_Unit1', 'Channel46_Unit1', 'Channel47_Unit1', 'Channel48_Unit1', 'Channel49_Unit1', 'Channel50_Unit1', 'Channel51_Unit1', 'Channel51_Unit2', 'Channel52_Unit1', 'Channel53_Unit1', 'Channel54_Unit1', 'Channel55_Unit2', 'Channel56_Unit1', 'Channel57_Unit1', 'Channel58_Unit1', 'Channel59_Unit1', 'Channel60_Unit1', 'Channel61_Unit1', 'Channel62_Unit1', 'Channel63_Unit1', 'Channel64_Unit1', 'Channel65_Unit1', 'Channel66_Unit1', 'Channel67_Unit1', 'Channel68_Unit1', 'Channel68_Unit2', 'Channel69_Unit1', 'Channel6_Unit1', 'Channel71_Unit2', 'Channel72_Unit1', 'Channel73_Unit1', 'Channel75_Unit1', 'Channel76_Unit1', 'Channel77_Unit1', 'Channel78_Unit1', 'Channel79_Unit1', 'Channel79_Unit2', 'Channel81_Unit1', 'Channel81_Unit2', 'Channel83_Unit1', 'Channel85_Unit1', 'Channel85_Unit2', 'Channel86_Unit1', 'Channel88_Unit1', 'Channel90_Unit1', 'Channel91_Unit1', 'Channel92_Unit1', 'Channel93_Unit2', 'Channel93_Unit3', 'Channel94_Unit1', 'Channel95_Unit1')\n"
     ]
    }
   ],
   "source": [
    "print(sort_mov_channames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_avg_data_mov = np.mean(raster_movie, axis=2)\n",
    "sem_mov = scipy.stats.sem(raster_movie, axis=2)\n",
    "\n",
    "trial_avg_data_img = np.mean(raster_image, axis=2)\n",
    "sem_img = scipy.stats.sem(raster_image, axis=2)\n",
    "\n",
    "for i in range(len(sort_mov_channames)):\n",
    "    \n",
    "    mov_ind = sort_mov_indexes[i]\n",
    "    mov_name = sort_mov_channames[i]\n",
    "\n",
    "    img_ind = sort_img_indexes[i]\n",
    "    img_name = sort_img_channames[i]\n",
    "\n",
    "    fig, plt.figure()\n",
    "\n",
    "    plt.plot(np.arange(trial_avg_data_mov.shape[1]),trial_avg_data_mov[mov_ind])\n",
    "    plt.fill_between(np.arange(trial_avg_data_mov.shape[1]),trial_avg_data_mov[mov_ind]+1.96*sem_mov[mov_ind], trial_avg_data_mov[mov_ind]-1.96*sem_mov[mov_ind], alpha=0.5)\n",
    "\n",
    "    #plt.plot(trial_avg_movie[value[0]])\n",
    "    plt.title(f'{mov_name} , Movie')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    fig, plt.figure()\n",
    "\n",
    "    plt.plot(np.arange(trial_avg_data_img.shape[1]),trial_avg_data_img[img_ind])\n",
    "    plt.fill_between(np.arange(trial_avg_data_img.shape[1]),trial_avg_data_img[img_ind]+1.96*sem_img[img_ind], trial_avg_data_img[img_ind]-1.96*sem_img[img_ind], alpha=0.5)\n",
    "\n",
    "    #plt.plot(trial_avg_movie[value[0]])\n",
    "    plt.title(f'{img_name} , Image')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_stim_indexes = {}\n",
    "\n",
    "for i in range(len(movie_names)):\n",
    "\n",
    "    mov = movie_names[i]\n",
    "    if not mov in mov_stim_indexes.keys():\n",
    "        mov_stim_indexes[mov] = [i]\n",
    "\n",
    "    else:\n",
    "        mov_stim_indexes[mov].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_movies_by_channel(raster_movie, movie, channelname, channelindex, mov_stim_indexes):\n",
    "\n",
    "    fig, axs = plt.subplots(4,3)\n",
    "\n",
    "    channel_data = np.squeeze(raster_movie[channelindex,:,:]) # time_bins x trials\n",
    "\n",
    "    mov_opts = ['sped', 'first']\n",
    "    mov_perts = ['original', 'inverted', 'noise']\n",
    "\n",
    "    for i in len(mov_opts):\n",
    "        for j in len(mov_perts):\n",
    "\n",
    "            norm_name = f\"{movie}_{mov_opts[i]}_{mov_perts[j]}\"\n",
    "            shuffle_name = f\"{movie}_{mov_opts[i]}_{mov_perts[j]}_shuffle\"\n",
    "\n",
    "            norm_mov_inds = mov_stim_indexes[norm_name]\n",
    "            shuffle_mov_inds = mov_stim_indexes[shuffle_name]\n",
    "\n",
    "            norm_mov_trials = channel_data[:, norm_mov_inds]\n",
    "            shuffle_mov_trials = channel_data[:, shuffle_mov_inds]\n",
    "\n",
    "            norm_avg = np.mean(norm_mov_trials, axis=1)\n",
    "            shuffle_avg = np.mean(shuffle_mov_trials, axis=1)\n",
    "\n",
    "            norm_sem = scipy.stats.sem(norm_mov_trials, axis=1)\n",
    "            shuffle_sem = scipy.stats.sem(shuffle_mov_trials, axis=1)\n",
    "\n",
    "            axs[i*2,j].plot(norm_avg)\n",
    "            axs[i*2,j].fill_between(np.arange(len(norm_avg), norm_avg+1.96*norm_sem, norm_avg-1.96*norm_sem))\n",
    "\n",
    "            if i == 0:\n",
    "                axs[i*2,j].set_title(f\"{mov_opts[1]}_{mov_perts[j]}\")\n",
    "                axs[i*2+1,j].set_title(f\"{mov_opts[1]}_{mov_perts[j]}_shuffle\")\n",
    "            else:\n",
    "                axs[i*2,j].set_title(f\"{mov_opts[0]}_{mov_perts[j]}\")\n",
    "                axs[i*2+1,j].set_title(f\"{mov_opts[0]}_{mov_perts[j]}_shuffle\")\n",
    "\n",
    "            axs[i*2+1,j].plot(shuffle_avg)\n",
    "            axs[i*2+1,j].fill_between(np.arange(len(shuffle_avg), shuffle_avg+1.96*shuffle_sem, shuffle_avg-1.96*shuffle_sem))\n",
    "\n",
    "    fig.suptitle(f\"PSTHs for {movie}, {channelname}\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.str_('ambulance_sped_inverted_shuffle'): [0, 34, 41, 109, 133, 150, 207],\n",
       " np.str_('komodo_first_original_shuffle'): [1, 46, 86, 124, 147, 182, 201],\n",
       " np.str_('komodo_first_noise_shuffle'): [2, 51, 106, 132, 154, 195],\n",
       " np.str_('komodo_first_original'): [3, 38, 95, 120, 158, 198],\n",
       " np.str_('ambulance_sped_noise_shuffle'): [4, 50, 77, 114, 162, 220, 224],\n",
       " np.str_('komodo_first_inverted'): [5, 57, 73, 74, 126, 156, 208],\n",
       " np.str_('ambulance_sped_original_shuffle'): [6, 65, 101, 121, 153, 185],\n",
       " np.str_('komodo_sped_noise_shuffle'): [7, 61, 83, 115, 163, 213],\n",
       " np.str_('ambulance_sped_noise'): [8, 66, 93, 122, 172, 191],\n",
       " np.str_('ambulance_sped_inverted'): [9, 49, 85, 127, 166, 192, 221],\n",
       " np.str_('komodo_sped_inverted_shuffle'): [10, 56, 97, 113, 164, 200],\n",
       " np.str_('macaque_eating_sped_inverted'): [11, 54, 94, 143, 183, 187],\n",
       " np.str_('macaque_eating_first_inverted'): [12, 52, 100, 138, 175, 216],\n",
       " np.str_('ambulance_first_noise_shuffle'): [13, 69, 82, 112, 159, 189],\n",
       " np.str_('komodo_first_noise'): [14, 55, 99, 129, 168, 188],\n",
       " np.str_('macaque_eating_sped_original_shuffle'): [15, 37, 103, 139, 149, 196],\n",
       " np.str_('macaque_eating_sped_inverted_shuffle'): [16, 67, 96, 116, 148, 218],\n",
       " np.str_('ambulance_first_original'): [17, 62, 75, 140, 152, 212],\n",
       " np.str_('ambulance_first_inverted'): [18, 70, 108, 125, 151, 186],\n",
       " np.str_('komodo_sped_original_shuffle'): [19, 63, 107, 123, 179, 194, 223],\n",
       " np.str_('ambulance_sped_original'): [20, 60, 104, 144, 160, 190, 222],\n",
       " np.str_('macaque_eating_first_noise_shuffle'): [21,\n",
       "  59,\n",
       "  105,\n",
       "  110,\n",
       "  128,\n",
       "  171,\n",
       "  217],\n",
       " np.str_('komodo_sped_noise'): [22, 43, 81, 118, 169, 203],\n",
       " np.str_('macaque_eating_first_noise'): [23, 39, 80, 146, 177, 209],\n",
       " np.str_('ambulance_first_inverted_shuffle'): [24, 44, 90, 117, 165, 202],\n",
       " np.str_('ambulance_first_noise'): [25, 68, 89, 134, 161, 204],\n",
       " np.str_('macaque_eating_sped_noise_shuffle'): [26, 48, 79, 131, 155, 206],\n",
       " np.str_('komodo_sped_original'): [27, 53, 78, 130, 178, 214],\n",
       " np.str_('komodo_first_inverted_shuffle'): [28, 64, 88, 145, 157, 184, 197],\n",
       " np.str_('macaque_eating_sped_noise'): [29, 71, 92, 142, 170, 205],\n",
       " np.str_('macaque_eating_first_inverted_shuffle'): [30,\n",
       "  42,\n",
       "  102,\n",
       "  137,\n",
       "  174,\n",
       "  199],\n",
       " np.str_('komodo_sped_inverted'): [31, 45, 84, 135, 167, 210],\n",
       " np.str_('macaque_eating_first_original_shuffle'): [32, 58, 98, 111, 176, 211],\n",
       " np.str_('macaque_eating_sped_original'): [33, 72, 76, 119, 173, 219],\n",
       " np.str_('ambulance_first_original_shuffle'): [35, 40, 91, 141, 181, 193],\n",
       " np.str_('macaque_eating_first_original'): [36, 47, 87, 136, 180, 215]}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mov_stim_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nwb-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
