{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer .features.Conv2d10 Sampled 256 units from feature tensor of shape (256, 13, 13)\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries \n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\Alireza\\Documents\\Git\\Cosine-Project\")\n",
    "from inSilico_experiments.utils.func_lib import *\n",
    "import matplotlib.pylab as plt\n",
    "##\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # becairfull with this\n",
    "#%%\n",
    "# parameters parsing\n",
    "# \n",
    "NUM_OF_RUNS_PER_POP_SIZE = 1\n",
    "NUM_OF_RUNS_PER_IMAGE = 1\n",
    "NUM_OF_RUN_RER_SUBPOAP = 1\n",
    "\n",
    "#%%\n",
    "# set main fynction\n",
    "if __name__==\"__main__\":\n",
    "    #%%\n",
    "    #import datetime\n",
    "    now = datetime.now()\n",
    "    from core.utils.GAN_utils import upconvGAN\n",
    "    from core.utils.Optimizers import CholeskyCMAES\n",
    "    from core.utils.grad_RF_estim import fit_2dgauss, GAN_grad_RF_estimate\n",
    "    from core.utils.CNN_scorers import TorchScorer, resize_and_pad_tsr\n",
    "    #%% \n",
    "    # Set parameters\n",
    "    date_time_str = now.strftime(\"%Y-%m-%d_%H-%M\")\n",
    "    refimgdir = r\"C:\\Data\\cosine\\insilico_experiments\\data\\image_net_tiny\"\n",
    "    exp_result_root = r\"C:\\Data\\cosine\\insilico_experiments\\Most_active_vs_random\\results\\rotated_%s\" % date_time_str\n",
    "    os.makedirs(exp_result_root, exist_ok=True)\n",
    "\n",
    "    net_name = \"alexnet\"\n",
    "    layer_name = \".features.Conv2d10\"\n",
    "    layer_short = \"conv5\"\n",
    "    gan_name = \"fc6\"\n",
    "    pop_size = [16, 64, 128, 256]\n",
    "    metric_name = [\"cosine\", \"MSE\"]\n",
    "    input_size = (3, 227, 227)\n",
    "    img_size = (187, 187)\n",
    "    pading_size = (20, 20) \n",
    "    #%% make a dictionary of the parameters\n",
    "    param_dict = {\"net_name\": net_name,\n",
    "                    \"layer_name\": layer_name,\n",
    "                    \"layer_short\": layer_short,\n",
    "                    \"gan_name\": gan_name,\n",
    "                    \"pop_size\": pop_size,\n",
    "                    \"input_size\": input_size,\n",
    "                    \"pading_size\": pading_size}\n",
    "    trial_param_dict = param_dict.copy()\n",
    "    #%% set up a pandas dataframe to save the inforamtions about each run\n",
    "    expriment_meta_data_df = pd.DataFrame(columns=[\"output_type\", \"trget_imge_name\", \"similarity_metric\", \"pop_size\", \"pop_resampling_id\",\n",
    "                                       \"gan_name\", \"layer_name\", \"layer_short\", \"net_name\", \"img_size\", \"pading_size\", \"input_size\", \"score\",\"pop_unit_idx\",\n",
    "                                       \"gen_rerun_id\", \"sub_pop_type\", \"sub_pop_size\", \"sub_pop_re_run_id\", \"save_dir_root\", \"file_name\"])\n",
    "\n",
    "    #%% save the parameters\n",
    "    #%% Load the reference images\n",
    "    refimgnms, refimgtsr = load_ref_imgs(\n",
    "        imgdir=refimgdir, preprocess_type='center_crop', image_size=227)\n",
    "    #%% Set up the scorer and the population\n",
    "    scorer = TorchScorer(net_name)\n",
    "    module_names, module_types, module_spec = get_module_names(\n",
    "        scorer.model, input_size, \"cuda\", False)\n",
    "\n",
    "    # %% set up the GAN\n",
    "    G = upconvGAN(gan_name).cuda()\n",
    "    G.requires_grad_(False)\n",
    "    code_length = G.codelen\n",
    "    \n",
    "    #%% Run the experiment\n",
    "    scorer = TorchScorer(net_name)\n",
    "\n",
    "    unit_mask_dict, unit_tsridx_dict = set_random_population_recording(\n",
    "                scorer, [layer_name], randomize=False)\n",
    "    # Encode a population of images to set the normalizer and mask.\n",
    "    ref_actmat, _ = encode_image(scorer, refimgtsr, key=layer_name,\n",
    "                            RFresize=True, corner=pading_size, imgsize=img_size)    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_most_active_population_recording(scorer_most, targetnames, refimgtsr, corner_pading, img_size, popsize=500, single_col=True, resample=False,\n",
    "                                    seed=None):\n",
    "    most_active_unit_tsridx_dict = {}\n",
    "    most_active_unit_mask_dict = {}\n",
    "    module_names, module_types, module_spec = get_module_names(scorer_most.model, (3,227,227), \"cuda\", False)\n",
    "    invmap = {v: k for k, v in module_names.items()}\n",
    "    try:\n",
    "        for layer in targetnames:\n",
    "            outshape = module_spec[invmap[layer]][\"outshape\"]\n",
    "\n",
    "            flat_idx_all = sample_center_column_units_idx(outshape, single_col=True)\n",
    "            scorer_most.set_popul_recording(layer, flat_idx_all, )\n",
    "            ref_actmat, _ = encode_image(scorer_most, refimgtsr, key=layer,\n",
    "                            RFresize=True, corner=corner_pading, imgsize=img_size)   \n",
    "            # get popsiz elements largest values of ref_actmat\n",
    "            most_actve_unit_idx = np.argsort(ref_actmat, axis=None)[-popsize:] \n",
    "            flat_idx_most_actve = flat_idx_all[most_actve_unit_idx]\n",
    "\n",
    "            scorer_most.cleanup(print_info=False)\n",
    "        \n",
    "            tsr_idx_most_active = np.unravel_index(flat_idx_most_actve, outshape)\n",
    "            most_active_unit_mask_dict[layer] = flat_idx_most_actve\n",
    "            most_active_unit_tsridx_dict[layer] = tsr_idx_most_active\n",
    "            scorer_most.set_popul_recording(layer, flat_idx_most_actve, )\n",
    "\n",
    "    except KeyError:\n",
    "        print(*invmap.keys(), sep=\"\\n\")\n",
    "        raise KeyError\n",
    "    return most_active_unit_mask_dict, most_active_unit_tsridx_dict\n",
    "\n",
    "\n",
    "def set_least_active_population_recording(scorer_least, targetnames, refimgtsr, corner_pading, img_size, popsize=500, single_col=True, resample=False,\n",
    "                                    seed=None):\n",
    "    least_active_unit_tsridx_dict = {}\n",
    "    least_active_unit_mask_dict = {}\n",
    "    module_names, module_types, module_spec = get_module_names(scorer_least.model, (3,227,227), \"cuda\", False)\n",
    "    invmap = {v: k for k, v in module_names.items()}\n",
    "    try:\n",
    "        for layer in targetnames:\n",
    "            outshape = module_spec[invmap[layer]][\"outshape\"]\n",
    "\n",
    "            flat_idx_all = sample_center_column_units_idx(outshape, single_col=True)\n",
    "            scorer_least.set_popul_recording(layer, flat_idx_all, )\n",
    "            ref_actmat, _ = encode_image(scorer_least, refimgtsr, key=layer,\n",
    "                            RFresize=True, corner=corner_pading, imgsize=img_size)   \n",
    "            # get popsiz elements smallest values of ref_actmat\n",
    "            least_actve_unit_idx = np.argsort(ref_actmat, axis=None)[:popsize]\n",
    "            \n",
    "            flat_idx_least_actve = flat_idx_all[least_actve_unit_idx]\n",
    "            \n",
    "            scorer_least.cleanup(print_info=False)\n",
    "        \n",
    "            tsr_idx_most_active = np.unravel_index(flat_idx_least_actve, outshape)\n",
    "            least_active_unit_mask_dict[layer] = flat_idx_least_actve\n",
    "            least_active_unit_tsridx_dict[layer] = tsr_idx_most_active\n",
    "            scorer_least.set_popul_recording(layer, flat_idx_least_actve, )\n",
    "\n",
    "    except KeyError:\n",
    "        print(*invmap.keys(), sep=\"\\n\")\n",
    "        raise KeyError\n",
    "    return least_active_unit_mask_dict, least_active_unit_tsridx_dict\n",
    "#%% let test the function\n",
    "imgid = 0\n",
    "scorer = TorchScorer(net_name)\n",
    "unit_mask_dict, unit_tsridx_dict, ref_actmat, most_actve_unit_idx = set_least_active_population_recording(scorer, [layer_name], refimgtsr[imgid:imgid + 1], pading_size, img_size, popsize=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_actmat_best, _ = encode_image(scorer, refimgtsr, key=layer_name,\n",
    "                            RFresize=True, corner=pading_size, imgsize=img_size)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-18.43441  , -18.400341 , -18.011045 , -17.981722 , -17.616796 ,\n",
       "       -17.582958 , -17.37425  , -17.137459 , -17.0347   , -16.739782 ,\n",
       "       -16.04295  , -15.9975195, -15.690247 , -15.441564 , -15.19063  ,\n",
       "       -14.986549 , -14.976959 , -14.661179 , -14.627042 , -14.396803 ,\n",
       "       -14.285725 , -14.157491 , -13.895635 , -13.751593 , -13.669177 ,\n",
       "       -13.331209 , -13.30969  , -13.302381 , -13.201684 , -13.070899 ,\n",
       "       -12.98473  , -12.928744 , -12.927791 , -12.917333 , -12.863702 ,\n",
       "       -12.85152  , -12.797337 , -12.590782 , -12.555866 , -12.500052 ,\n",
       "       -12.454038 , -12.431001 , -12.405144 , -12.327293 , -12.161742 ,\n",
       "       -12.108588 , -12.048702 , -11.946264 , -11.92395  , -11.861829 ,\n",
       "       -11.843388 , -11.832071 , -11.715294 , -11.714884 , -11.660082 ,\n",
       "       -11.403873 , -11.336632 , -11.31639  , -11.2299385, -11.207528 ,\n",
       "       -11.133642 , -11.080625 , -10.898127 , -10.746104 , -10.690709 ,\n",
       "       -10.67484  , -10.609883 , -10.559575 , -10.558177 , -10.509352 ,\n",
       "       -10.438896 , -10.354619 , -10.261704 , -10.252055 , -10.227297 ,\n",
       "       -10.2135515, -10.155993 , -10.15504  ,  -9.964633 ,  -9.855642 ,\n",
       "        -9.834702 ,  -9.714561 ,  -9.696815 ,  -9.685542 ,  -9.674324 ,\n",
       "        -9.640558 ,  -9.540288 ,  -9.496276 ,  -9.44537  ,  -9.352208 ,\n",
       "        -9.266072 ,  -9.26479  ,  -9.24223  ,  -9.083113 ,  -9.075113 ,\n",
       "        -9.053605 ,  -8.899952 ,  -8.853829 ,  -8.803746 ,  -8.774308 ,\n",
       "        -8.772919 ,  -8.76239  ,  -8.747638 ,  -8.430324 ,  -8.24354  ,\n",
       "        -8.206713 ,  -8.166846 ,  -8.13456  ,  -8.113423 ,  -7.981173 ,\n",
       "        -7.979527 ,  -7.9582067,  -7.8744864,  -7.817919 ,  -7.7972956,\n",
       "        -7.7547727,  -7.747138 ,  -7.731044 ,  -7.634864 ,  -7.5999165,\n",
       "        -7.5974984,  -7.5743484,  -7.495249 ,  -7.4150753,  -7.411231 ,\n",
       "        -7.336232 ,  -7.2852044,  -7.2199507], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print ref_actmat_best sorted\n",
    "np.sort(ref_actmat_best[0,:])\n",
    "#%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-18.434404 , -18.400337 , -18.01104  , -17.981714 , -17.61679  ,\n",
       "       -17.582958 , -17.374247 , -17.137453 , -17.034695 , -16.739786 ,\n",
       "       -16.04294  , -15.9975195, -15.690246 , -15.44156  , -15.190626 ,\n",
       "       -14.9865465, -14.976962 , -14.66117  , -14.6270485, -14.396799 ,\n",
       "       -14.285722 , -14.157482 , -13.895637 , -13.751583 , -13.669168 ,\n",
       "       -13.331206 , -13.309689 , -13.302379 , -13.201688 , -13.070895 ,\n",
       "       -12.984735 , -12.928741 , -12.927787 , -12.917329 , -12.863696 ,\n",
       "       -12.851512 , -12.79734  , -12.59078  , -12.555859 , -12.500049 ,\n",
       "       -12.454038 , -12.431    , -12.40514  , -12.327299 , -12.161738 ,\n",
       "       -12.108587 , -12.048702 , -11.946255 , -11.923947 , -11.861823 ,\n",
       "       -11.8433895, -11.832066 , -11.715292 , -11.71488  , -11.660072 ,\n",
       "       -11.4038725, -11.336632 , -11.316391 , -11.229938 , -11.207526 ,\n",
       "       -11.133646 , -11.080623 , -10.89812  , -10.746106 , -10.690702 ,\n",
       "       -10.674842 , -10.609886 , -10.559575 , -10.558171 , -10.509355 ,\n",
       "       -10.438884 , -10.354617 , -10.261693 , -10.2520485, -10.227298 ,\n",
       "       -10.2135515, -10.156003 , -10.15504  ,  -9.964638 ,  -9.855642 ,\n",
       "        -9.834694 ,  -9.7145605,  -9.696805 ,  -9.685537 ,  -9.674328 ,\n",
       "        -9.640553 ,  -9.540286 ,  -9.49628  ,  -9.445363 ,  -9.352204 ,\n",
       "        -9.266077 ,  -9.264788 ,  -9.242231 ,  -9.083109 ,  -9.075113 ,\n",
       "        -9.0536   ,  -8.899943 ,  -8.853829 ,  -8.803742 ,  -8.774299 ,\n",
       "        -8.772919 ,  -8.762391 ,  -8.747638 ,  -8.430323 ,  -8.243538 ,\n",
       "        -8.20671  ,  -8.1668415,  -8.134564 ,  -8.113425 ,  -7.98117  ,\n",
       "        -7.979522 ,  -7.9582105,  -7.8744836,  -7.817917 ,  -7.797289 ,\n",
       "        -7.7547717,  -7.747133 ,  -7.731044 ,  -7.634859 ,  -7.599921 ,\n",
       "        -7.597501 ,  -7.5743513,  -7.495249 ,  -7.4150763,  -7.4112315,\n",
       "        -7.336231 ,  -7.2852044,  -7.2199473], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_actmat[0,most_actve_unit_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for popsize in pop_size:\n",
    "        #%% add the population size to the dictionary\n",
    "        trial_param_dict = param_dict.copy()\n",
    "        trial_param_dict[\"pop_size\"] = popsize\n",
    "        trial_param_dict[\"sub_pop_type\"] = \"whole\"\n",
    "        #%% Set the population\n",
    "        for pop_resampling_id in range(NUM_OF_RUNS_PER_POP_SIZE):\n",
    "            # add the population resampling id to the dictionary\n",
    "            trial_param_dict[\"pop_resampling_id\"] = pop_resampling_id\n",
    "            # Set scorer and select population    \n",
    "            \n",
    "            unit_mask_dict, unit_tsridx_dict = set_random_population_recording(\n",
    "                scorer, [layer_name], popsize=popsize, seed=pop_resampling_id)\n",
    "            ## add the population unit index to the dictionary\n",
    "            trial_param_dict[\"pop_unit_idx\"] = unit_mask_dict[layer_name]\n",
    "            # Encode a population of images to set the normalizer and mask.\n",
    "            ref_actmat, _ = encode_image(scorer, refimgtsr, key=layer_name,\n",
    "                                    RFresize=True, corner=pading_size, imgsize=img_size)\n",
    "            popul_m, popul_s = set_normalizer(ref_actmat)\n",
    "            popul_mask = set_popul_mask(ref_actmat)\n",
    "            # receptive field estimation\n",
    "            unitslice = (unit_tsridx_dict[layer_name][0],\n",
    "                        unit_tsridx_dict[layer_name][1][0],\n",
    "                        unit_tsridx_dict[layer_name][2][0])\n",
    "            gradAmpmap = GAN_grad_RF_estimate(G, scorer.model, layer_name, unitslice, input_size=input_size,\n",
    "                                        device=\"cuda\", show=False, reps=100, batch=1)\n",
    "            fitdict = fit_2dgauss(gradAmpmap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosine-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
