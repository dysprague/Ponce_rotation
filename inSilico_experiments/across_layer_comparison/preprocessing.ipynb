{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatnation the data frames for the most active neurons recorded in each layer\n",
    "import pandas as pd\n",
    "import os\n",
    "# First let read all metadata data frames and concatenate them into one with one extera column for the image root path and one for the image folder\n",
    "data_root_batch1 = r\"N:\\PonceLab\\Users\\Alireza\\insilico_experiments\\Alexnet_remonstration_across_different_layer_062023\\raw_data\\O2_cluster_exp_062023\\meta_data_files\"\n",
    "# read all metadata files in the folder and concatenate them into one\n",
    "# the metadata files are saved in h5 format with the key \"expriment_meta_data_df\"\n",
    "meta_data_df_batch1 = pd.DataFrame()\n",
    "for file in os.listdir(data_root_batch1):\n",
    "    if file.endswith(\".h5\") and \"most\" in file:\n",
    "        meta_data_df_batch1 = pd.concat([meta_data_df_batch1, pd.read_hdf(os.path.join(data_root_batch1, file), key=\"expriment_meta_data_df\")], axis=0)\n",
    "\n",
    "# read other batch of metadata files\n",
    "data_root_batch2 = r\"N:\\PonceLab\\Users\\Alireza\\insilico_experiments\\Alexnet_remonstration_across_different_layer_062023\\raw_data\\O2_cluster_exp_062123\\meta_data_files\"\n",
    "# read all metadata files in the formt of \"*_most_*.h5\" folder and concatenate them into one\n",
    "# the metadata files are saved in h5 format with the key \"expriment_meta_data_df\"\n",
    "meta_data_df_batch2 = pd.DataFrame()\n",
    "for file in os.listdir(data_root_batch2):\n",
    "    # we want to read all data with that have most in their name\n",
    "    if file.endswith(\".h5\") and \"most\" in file:\n",
    "        metadata_df = pd.read_hdf((data_root_batch2+ \"\\\\\"+ file), key=\"expriment_meta_data_df\")\n",
    "        # each file is saved with the name of the data folder with a suffix of a random number at the end of the name taht\n",
    "        # splited with \"_\" so we want to extract the data folder name from the file name and add it as a column to the metadata data frame\n",
    "        folder_name = file.split(\"_\")[1]\n",
    "        for si in file.split(\"_\")[2:-1]:\n",
    "            folder_name = folder_name +(\"_\"+si)\n",
    "\n",
    "        metadata_df[\"data_root\"] = os.path.join(r\"N:\\PonceLab\\Users\\Alireza\\insilico_experiments\\Alexnet_remonstration_across_different_layer_062023\\raw_data\\O2_cluster_exp_062123\",\n",
    "                                                folder_name)\n",
    "        # print humner of repited index in the metadata data frame\n",
    "        print(\"number of repited index in the metadata data frame: \", metadata_df.index.duplicated().sum())\n",
    "        meta_data_df_batch2 = pd.concat([meta_data_df_batch2, metadata_df], axis=0)\n",
    "\n",
    "# concatenate the two batches of metadata data frames with adding a column for the image root path and one for the image folder \n",
    "# which is diffrent for each batch \n",
    "# first concatenate the two batches with tracking the batch number\n",
    "meta_data_df_batch1[\"data_root\"] = r\"N:\\PonceLab\\Users\\Alireza\\insilico_experiments\\Alexnet_remonstration_across_different_layer_062023\\raw_data\\O2_cluster_exp_062023\"\n",
    "# concatenate the two batches\n",
    "metadata_df = pd.concat([meta_data_df_batch1, meta_data_df_batch2], axis=0)\n",
    "# save the metadata data frame\n",
    "saving_root = r\"N:\\PonceLab\\Users\\Alireza\\insilico_experiments\\Alexnet_remonstration_across_different_layer_062023\\post_processed\"\n",
    "metadata_df.to_hdf(os.path.join(saving_root, \"metadata_most_df.h5\"), key=\"metadata_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the l2 distance the data frames for the most active neurons recorded in each layer\n",
    "\t \n",
    "import glob\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\Alireza\\Documents\\Git\\Cosine-Project\")\n",
    "from inSilico_experiments.utils.func_lib import *\n",
    "from core.utils.CNN_scorers import TorchScorer\n",
    "from inSilico_experiments.utils.pothook_analysis_lib import *\n",
    "\n",
    "\n",
    "\n",
    "network_list = ['alexnet', 'vgg16', 'resnet50', 'resnet101']\n",
    "# make a dict of modek name and models scorer\n",
    "scorer_dict = dict()\n",
    "for net_name in network_list:\n",
    "    scorer_dict[net_name] = TorchScorer(net_name)\n",
    "    metadata_df[net_name] = np.nan\n",
    "\n",
    "# add a new column to the dataframe to store the l2 distance between the generated image and the target image\n",
    "metadata_df[\"l2_distance\"] = np.nan\n",
    "row_count = 0\n",
    "# loop over all rows of the meta data dataframe\n",
    "for i, row in metadata_df.iterrows():\n",
    "    if row[\"output_type\"] == \"best_gen_imgs_RF_masked\":\n",
    "        # load the image as tensor\n",
    "        img_path = glob.glob(os.path.join(row[\"data_root\"], f\"{i}.jpg\"))[0]\n",
    "        img = Image.open(img_path)\n",
    "        gen_image_tensor = ToTensor()(img)\n",
    "        # find target image id and load the image as tensor\n",
    "        i_target = find_target_image_id(metadata_df, row)\n",
    "        # load the target image as tensor\n",
    "        img_path = glob.glob(os.path.join(row[\"data_root\"], f\"{i_target}.jpg\"))[0]\n",
    "        img = Image.open(img_path)\n",
    "        target_image_tensor = ToTensor()(img)    \n",
    "        # plot the generated image and the target image in a figure to make sure that they are the same\n",
    "        '''fig, ax = plt.subplots(1, 2)\n",
    "        ax[0].imshow(ToPILImage()(gen_image_tensor))\n",
    "        ax[1].imshow(ToPILImage()(target_image_tensor))\n",
    "        plt.show()'''\n",
    "        # calculate the l2 distance between the generated image and the target image and store it in the dataframe\n",
    "        metadata_df.loc[i, \"l2_distance\"] = l2_distance(gen_image_tensor, target_image_tensor).item()\n",
    "        #get_similarty_score_by_CNN(gen_image_tensor, target_image_tensor, scorer_dict, metadata_df, i)\n",
    "        row_count = row_count + 1\n",
    "        \n",
    "metadata_df.to_hdf(os.path.join(saving_root, \"metadata_most_df_with_similarity.h5\"), key=\"metadata_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "sys.path.append(r\"C:\\Users\\Alireza\\Documents\\Git\\Cosine-Project\")\n",
    "from inSilico_experiments.utils.func_lib import *\n",
    "from inSilico_experiments.utils.CosineDataset import *\n",
    "from inSilico_experiments.utils.pothook_analysis_lib import *\n",
    "\n",
    "\n",
    "# implimenting torch data loader\n",
    "data_path = r\"N:\\PonceLab\\Users\\Alireza\\insilico_experiments\\Alexnet_remonstration_across_different_layer_062023\\post_processed\"\n",
    "metadata_df_most = pd.read_hdf(os.path.join(data_path, \"metadata_most_df.h5\"), key=\"metadata_df\")\n",
    "\n",
    "\n",
    "\n",
    "layer_short_list= metadata_df_most[\"layer_short\"].unique()\n",
    "# remove the NaN values from the layer_short_list\n",
    "layer_short_list = layer_short_list[~pd.isnull(layer_short_list)]\n",
    "similarity_metric_list = metadata_df_most[\"similarity_metric\"].unique()\n",
    "# remove the NaN values from the similarity_metric_list\n",
    "similarity_metric_list = similarity_metric_list[~pd.isnull(similarity_metric_list)]\n",
    "\n",
    "pop_size_list = metadata_df_most[\"pop_size\"].unique()\n",
    "# remove the NaN values from the pop_size_list\n",
    "pop_size_list = np.sort(pop_size_list[~pd.isnull(pop_size_list)])\n",
    "\n",
    "gen_rerun_id_list = metadata_df_most[\"gen_rerun_id\"].unique()\n",
    "# remove the NaN values from the gen_rerun_id_list\n",
    "gen_rerun_id_list = np.sort(gen_rerun_id_list[~pd.isnull(gen_rerun_id_list)])\n",
    "\n",
    "pop_resampling_id_list = metadata_df_most[\"pop_resampling_id\"].unique()\n",
    "# remove the NaN values from the pop_resampling_id_list\n",
    "pop_resampling_id_list = np.sort(pop_resampling_id_list[~pd.isnull(pop_resampling_id_list)])\n",
    "\n",
    "smpling_type_list = metadata_df_most[\"sub_pop_type\"].unique()\n",
    "# remove the NaN values from the smpling_type_list\n",
    "smpling_type_list = smpling_type_list[~pd.isnull(smpling_type_list)]\n",
    "\n",
    "# loop over pop_size_list and sampling_type and layer_short_list and similarity_metric_list \n",
    "\n",
    "for layer_short in layer_short_list:\n",
    "    for similarity_metric in similarity_metric_list:\n",
    "        for pop_size in pop_size_list:\n",
    "            for sampling_type in smpling_type_list:\n",
    "                sub_meta_df = metadata_df_most[\\\n",
    "                    (metadata_df_most[\"output_type\"] == \"best_gen_imgs_RF_masked\") & (\n",
    "                    metadata_df_most[\"layer_short\"]==layer_short) & (\n",
    "                    metadata_df_most[\"sub_pop_type\"] == smpling_type) & (\n",
    "                    metadata_df_most[\"similarity_metric\"] == similarity_metric) & ( \n",
    "                    metadata_df_most[\"trget_imge_name\"] == image_name)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layer_short_list= metadata_df_most[\"layer_short\"].unique()\n",
    "# remove the NaN values from the layer_short_list\n",
    "similarity_metric = \"cosine\"\n",
    "pop_size = 32\n",
    "gen_rerun_id = 0\n",
    "output_type = \"best_gen_imgs_RF_masked\"\n",
    "RF_treshold = 2\n",
    "pop_resampling_id = 0\n",
    "smpling_type = \"random\"\n",
    "sub_meta_df = metadata_df_most[\\\n",
    "                (metadata_df_most[\"output_type\"] == \"best_gen_imgs_RF_masked\") & (\n",
    "                metadata_df_most[\"layer_short\"]==layer_short) & (\n",
    "                metadata_df_most[\"sub_pop_type\"] == smpling_type) & (\n",
    "                metadata_df_most[\"similarity_metric\"] == similarity_metric) & ( \n",
    "                metadata_df_most[\"trget_imge_name\"] == image_name)]\n",
    "path_list = [os.path.join(sub_meta_df[\"data_root\"][i], f\"{sub_meta_df.index[i]}.jpg\") for i in range(len(sub_meta_df))]\n",
    "label_list = sub_meta_df.index.values\n",
    "\n",
    "transform = Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "dataset = SimpleDataset(path_list, label_list, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=10, num_workers=5)\n",
    "\n",
    "for i, data in enumerate(dataloader):\n",
    "    print(i, data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatnation the data frames for the random active neurons recorded in each layer\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "# First let read all metadata data frames and concatenate them into one with one extera column for the image root path and one for the image folder\n",
    "# read other batch of metadata files\n",
    "data_root_batch = r\"N:\\PonceLab\\Users\\Alireza\\insilico_experiments\\Alexnet_remonstration_across_different_layer_062023\\raw_data\\O2_cluster_exp_062123\\meta_data_files\"\n",
    "# read all metadata files in the formt of \"*_most_*.h5\" folder and concatenate them into one\n",
    "# the metadata files are saved in h5 format with the key \"expriment_meta_data_df\"\n",
    "meta_data_df_batch = pd.DataFrame()\n",
    "for file in os.listdir(data_root_batch):\n",
    "    # we want to read all data with that have most in their name\n",
    "    if file.endswith(\".h5\") and \"random\" in file:\n",
    "        #print(f\"reading file {file}\")\n",
    "        metadata_df = pd.read_hdf((data_root_batch+ \"\\\\\"+ file), key=\"expriment_meta_data_df\")\n",
    "        # each file is saved with the name of the data folder with a suffix of a random number at the end of the name taht\n",
    "        # splited with \"_\" so we want to extract the data folder name from the file name and add it as a column to the metadata data frame\n",
    "        folder_name = file.split(\"_\")[1]\n",
    "        for si in file.split(\"_\")[2:-1]:\n",
    "            folder_name = folder_name +(\"_\"+si)\n",
    "\n",
    "        metadata_df[\"data_root\"] = os.path.join(r\"N:\\PonceLab\\Users\\Alireza\\insilico_experiments\\Alexnet_remonstration_across_different_layer_062023\\raw_data\\O2_cluster_exp_062123\",\n",
    "                                                folder_name)\n",
    "        print(\"number of repited index in the metadata data frame: \", metadata_df.index.duplicated().sum())\n",
    "        meta_data_df_batch = pd.concat([meta_data_df_batch, metadata_df], axis=0)\n",
    "\n",
    "metadata_df = meta_data_df_batch\n",
    "# save the metadata data frame\n",
    "\n",
    "saving_root = r\"N:\\PonceLab\\Users\\Alireza\\insilico_experiments\\Alexnet_remonstration_across_different_layer_062023\\post_processed\"\n",
    "metadata_df.to_hdf(os.path.join(saving_root, \"metadata_random_df.h5\"), key=\"metadata_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the l2 distance the data frames for the random  active neurons recorded in each layer \n",
    "import glob\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\Alireza\\Documents\\Git\\Cosine-Project\")\n",
    "from inSilico_experiments.utils.func_lib import *\n",
    "from core.utils.CNN_scorers import TorchScorer\n",
    "from inSilico_experiments.utils.pothook_analysis_lib import *\n",
    "\n",
    "\n",
    "\n",
    "#network_list = ['alexnet', 'vgg16', 'resnet50', 'resnet101']\n",
    "# make a dict of modek name and models scorer\n",
    "#scorer_dict = dict()\n",
    "#for net_name in network_list:\n",
    "#    scorer_dict[net_name] = TorchScorer(net_name)\n",
    "#    metadata_df[net_name] = np.nan\n",
    "\n",
    "# add a new column to the dataframe to store the l2 distance between the generated image and the target image\n",
    "metadata_df[\"l2_distance\"] = np.nan\n",
    "row_count = 0\n",
    "# loop over all rows of the meta data dataframe\n",
    "for i, row in metadata_df.iterrows():\n",
    "    if row[\"output_type\"] == \"best_gen_imgs_RF_masked\":\n",
    "        # load the image as tensor\n",
    "        img_path = glob.glob(os.path.join(row[\"data_root\"], f\"{i}.jpg\"))[0]\n",
    "        img = Image.open(img_path)\n",
    "        gen_image_tensor = ToTensor()(img)\n",
    "        # find target image id and load the image as tensor\n",
    "        i_target = find_target_image_id(metadata_df, row)\n",
    "        # load the target image as tensor\n",
    "        img_path = glob.glob(os.path.join(row[\"data_root\"], f\"{i_target}.jpg\"))[0]\n",
    "        img = Image.open(img_path)\n",
    "        target_image_tensor = ToTensor()(img)    \n",
    "        # plot the generated image and the target image in a figure to make sure that they are the same\n",
    "        '''fig, ax = plt.subplots(1, 2)\n",
    "        ax[0].imshow(ToPILImage()(gen_image_tensor))\n",
    "        ax[1].imshow(ToPILImage()(target_image_tensor))\n",
    "        plt.show()'''\n",
    "        # calculate the l2 distance between the generated image and the target image and store it in the dataframe\n",
    "        try:\n",
    "            metadata_df.loc[i, \"l2_distance\"] = l2_distance(gen_image_tensor, target_image_tensor).item()\n",
    "        except:\n",
    "            print(f\"error in calculating l2 distance for raw: {i}\")\n",
    "        #get_similarty_score_by_CNN(gen_image_tensor, target_image_tensor, scorer_dict, metadata_df, i)\n",
    "        row_count = row_count + 1\n",
    "        \n",
    "metadata_df.to_hdf(os.path.join(saving_root, \"metadata_random_df_with_similarity.h5\"), key=\"metadata_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatnation the data frames for the neurons recorded across different layers\n",
    "import pandas as pd\n",
    "import os\n",
    "# First let read all metadata data frames and concatenate them into one with one extera column for the image root path and one for the image folder\n",
    "# read other batch of metadata files\n",
    "data_root_batch = r\"N:\\PonceLab\\Users\\Alireza\\insilico_experiments\\Alexnet_remonstration_across_different_layer_062023\\raw_data\\cross_layer_recording_o2_062823\\meta_data_files\"\n",
    "# read all metadata files in the formt of \"*_most_*.h5\" folder and concatenate them into one\n",
    "# the metadata files are saved in h5 format with the key \"expriment_meta_data_df\"\n",
    "meta_data_df_batch = pd.DataFrame()\n",
    "for file in os.listdir(data_root_batch):\n",
    "    # we want to read all data with that have most in their name\n",
    "    if file.endswith(\".h5\"):\n",
    "        #print(f\"reading file {file}\")\n",
    "        metadata_df = pd.read_hdf((data_root_batch+ \"\\\\\"+ file), key=\"expriment_meta_data_df\")\n",
    "        # each file is saved with the name of the data folder with a suffix of a random number at the end of the name taht\n",
    "        # splited with \"_\" so we want to extract the data folder name from the file name and add it as a column to the metadata data frame\n",
    "        folder_name = file.split(\"_\")[1]\n",
    "        for si in file.split(\"_\")[2:-1]:\n",
    "            folder_name = folder_name +(\"_\"+si)\n",
    "\n",
    "        metadata_df[\"data_root\"] = os.path.join(r\"N:\\PonceLab\\Users\\Alireza\\insilico_experiments\\Alexnet_remonstration_across_different_layer_062023\\raw_data\\cross_layer_recording_o2_062823\",\n",
    "                                                folder_name)\n",
    "        print(\"number of repited index in the metadata data frame: \", metadata_df.index.duplicated().sum())\n",
    "        meta_data_df_batch = pd.concat([meta_data_df_batch, metadata_df], axis=0)\n",
    "\n",
    "metadata_df = meta_data_df_batch\n",
    "# save the metadata data frame\n",
    "\n",
    "saving_root = r\"N:\\PonceLab\\Users\\Alireza\\insilico_experiments\\Alexnet_remonstration_across_different_layer_062023\\post_processed\"\n",
    "metadata_df.to_hdf(os.path.join(saving_root, \"metadata_cross_layer_recording_df.h5\"), key=\"metadata_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import glob\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\Alireza\\Documents\\Git\\Cosine-Project\")\n",
    "from inSilico_experiments.utils.func_lib import *\n",
    "from core.utils.CNN_scorers import TorchScorer\n",
    "from inSilico_experiments.utils.pothook_analysis_lib import *\n",
    "\n",
    "\n",
    "\n",
    "# add a new column to the dataframe to store the l2 distance between the generated image and the target image\n",
    "metadata_df[\"l2_distance\"] = np.nan\n",
    "row_count = 0\n",
    "# loop over all rows of the meta data dataframe\n",
    "for i, row in metadata_df.iterrows():\n",
    "    if row[\"output_type\"] == \"best_gen_imgs_RF_masked\":\n",
    "        # load the image as tensor\n",
    "        img_path = glob.glob(os.path.join(row[\"data_root\"], f\"{i}.jpg\"))[0]\n",
    "        img = Image.open(img_path)\n",
    "        gen_image_tensor = ToTensor()(img)\n",
    "        # find target image id and load the image as tensor\n",
    "        i_target = find_target_image_id(metadata_df, row)\n",
    "        # load the target image as tensor\n",
    "        img_path = glob.glob(os.path.join(row[\"data_root\"], f\"{i_target}.jpg\"))[0]\n",
    "        img = Image.open(img_path)\n",
    "        target_image_tensor = ToTensor()(img)    \n",
    "        # plot the generated image and the target image in a figure to make sure that they are the same\n",
    "        '''fig, ax = plt.subplots(1, 2)\n",
    "        ax[0].imshow(ToPILImage()(gen_image_tensor))\n",
    "        ax[1].imshow(ToPILImage()(target_image_tensor))\n",
    "        plt.show()'''\n",
    "        # calculate the l2 distance between the generated image and the target image and store it in the dataframe\n",
    "        try:\n",
    "            metadata_df.loc[i, \"l2_distance\"] = l2_distance(gen_image_tensor, target_image_tensor).item()\n",
    "        except:\n",
    "            print(f\"error in calculating l2 distance for raw: {i}\")\n",
    "        #get_similarty_score_by_CNN(gen_image_tensor, target_image_tensor, scorer_dict, metadata_df, i)\n",
    "        row_count = row_count + 1\n",
    "        \n",
    "metadata_df.to_hdf(os.path.join(saving_root, \"metadata_cross_layer_recording_with_similarity.h5\"), key=\"metadata_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alireza\\AppData\\Local\\Temp\\ipykernel_25564\\2337153699.py:72: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block3_values] [items->Index(['output_type', 'trget_imge_name', 'similarity_metric', 'gan_name',\n",
      "       'layer_name', 'layer_short', 'net_name', 'img_size', 'pading_size',\n",
      "       'input_size', 'pop_unit_idx', 'sub_pop_type', 'gen_rerun_id',\n",
      "       'data_root'],\n",
      "      dtype='object')]\n",
      "\n",
      "  metadata_df.to_hdf(os.path.join(data_path, \"metadata_df_with_sim_index_v2.h5\"), key=\"metadata_df\")\n",
      "C:\\Users\\Alireza\\AppData\\Local\\Temp\\ipykernel_25564\\2337153699.py:74: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block3_values] [items->Index(['output_type', 'trget_imge_name', 'similarity_metric', 'gan_name',\n",
      "       'layer_name', 'layer_short', 'net_name', 'img_size', 'pading_size',\n",
      "       'input_size', 'pop_unit_idx', 'sub_pop_type', 'gen_rerun_id',\n",
      "       'data_root'],\n",
      "      dtype='object')]\n",
      "\n",
      "  metadata_df.to_hdf(os.path.join(data_path, \"metadata_df_with_sim_index_v2.h5\"), key=\"metadata_df\")\n",
      "C:\\Users\\Alireza\\AppData\\Local\\Temp\\ipykernel_25564\\2337153699.py:75: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block3_values] [items->Index(['output_type', 'trget_imge_name', 'similarity_metric', 'gan_name',\n",
      "       'layer_name', 'layer_short', 'net_name', 'img_size', 'pading_size',\n",
      "       'input_size', 'pop_unit_idx', 'sub_pop_type', 'gen_rerun_id',\n",
      "       'data_root'],\n",
      "      dtype='object')]\n",
      "\n",
      "  metadata_df.to_hdf(os.path.join(data_path, \"metadata_df_with_sim_index_v2_final.h5\"), key=\"metadata_df\")\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\Alireza\\Documents\\Git\\Cosine-Project\")\n",
    "from inSilico_experiments.utils.func_lib import *\n",
    "from core.utils.CNN_scorers import TorchScorer\n",
    "from inSilico_experiments.utils.pothook_analysis_lib import *\n",
    "\n",
    "data_path = r\"N:\\PonceLab\\Users\\Alireza\\insilico_experiments\\Alexnet_remonstration_across_different_layer_062023\\post_processed\"\n",
    "\n",
    "metadata_df_cosine_intralayer = pd.read_hdf(os.path.join(data_path, \"metadata_df_inter_layer_with_normalized_dist.h5\"), key=\"metadata_df\")\n",
    "metadata_df_cosine_crosslayer = pd.read_hdf(os.path.join(data_path, \"metadata_df_intera_layer_with_normalized_dist.h5\"), key=\"metadata_df\")\n",
    "# concatenate the two dataframes\n",
    "metadata_df = pd.concat([metadata_df_cosine_intralayer, metadata_df_cosine_crosslayer], ignore_index=False)\n",
    "# concatenate the two dataframes\n",
    "\n",
    "RF_path = r\"N:\\PonceLab\\Users\\Alireza\\insilico_experiments\\Alexnet_remonstration_across_different_layer_062023\\post_processed\\rf_filters\"\n",
    "\n",
    "init_img_path = r\"N:\\PonceLab\\Users\\Alireza\\insilico_experiments\\Alexnet_remonstration_across_different_layer_062023\\post_processed\\init_img\\init_img.jpg\"\n",
    "init_img = Image.open(init_img_path)\n",
    "init_img = ToTensor()(init_img)\n",
    "\n",
    "# add a new column to the dataframe to store the l2 distance between the generated image and the target image\n",
    "metadata_df[\"sim_index\"] = np.nan\n",
    "row_count = 0\n",
    "# loop over all rows of the meta data dataframe\n",
    "for i, row in metadata_df.iterrows():\n",
    "    if row[\"output_type\"] == \"best_gen_imgs_RF_masked\":\n",
    "        # load the image as tensor\n",
    "        img_path = glob.glob(os.path.join(row[\"data_root\"], f\"{i}.jpg\"))[0]\n",
    "        img = Image.open(img_path)\n",
    "        gen_image_tensor = ToTensor()(img)\n",
    "        # find target image id and load the image as tensor\n",
    "        i_target = find_target_image_id(metadata_df, row)\n",
    "        # load the target image as tensor\n",
    "        img_path = glob.glob(os.path.join(row[\"data_root\"], f\"{i_target}.jpg\"))[0]\n",
    "        img = Image.open(img_path)\n",
    "        target_image_tensor = ToTensor()(img)    \n",
    "\n",
    "        if row[\"layer_short\"] == \"conv5432\":\n",
    "            layer_short = \"conv5\"\n",
    "            pop_size = row[\"pop_size\"]*4\n",
    "        elif row[\"layer_short\"] == \"conv53\":\n",
    "            layer_short = \"conv5\"\n",
    "            pop_size = row[\"pop_size\"]*2\n",
    "        else:\n",
    "            layer_short = row[\"layer_short\"]\n",
    "            pop_size = row[\"pop_size\"]\n",
    "        \n",
    "        RF_map = np.load(os.path.join(RF_path, f\"{layer_short}_{pop_size}.npz\"))\n",
    "\n",
    "        RF_filter = RF_map[\"fitmap\"] > RF_map[\"fitmap\"][int(RF_map[\"xo\"]+(1.5*RF_map[\"sigma_x\"])), int(RF_map[\"yo\"]+(1.5*RF_map[\"sigma_y\"]))]\n",
    "\n",
    "        init_img_rf_masked =\\\n",
    "            (torch.from_numpy(np.absolute(RF_map[\"fitmap\"][None,:,:])) / RF_map[\"fitmap\"].max()) *\\\n",
    "                    init_img\n",
    "        # calculate the l2 distance between the generated image and the target image and store it in the dataframe\n",
    "        try:\n",
    "            metadata_df.loc[i, \"sim_index_l1\"] = \\\n",
    "                        sim_index_l1(target_image_tensor, gen_image_tensor, init_img_rf_masked, RFfilter=np.array(RF_filter))\n",
    "            metadata_df.loc[i, \"sim_index_l2\"] = \\\n",
    "                        sim_index_l2(target_image_tensor, gen_image_tensor, init_img_rf_masked, RFfilter=np.array(RF_filter))\n",
    "        except:\n",
    "            print(f\"error in calculating l2 distance for raw: {i}\")\n",
    "        #get_similarty_score_by_CNN(gen_image_tensor, target_image_tensor, scorer_dict, metadata_df, i)\n",
    "        row_count = row_count + 1\n",
    "        if row_count % 1000 == 0:\n",
    "            metadata_df.to_hdf(os.path.join(data_path, \"metadata_df_with_sim_index_v2.h5\"), key=\"metadata_df\")\n",
    "        \n",
    "metadata_df.to_hdf(os.path.join(data_path, \"metadata_df_with_sim_index_v2.h5\"), key=\"metadata_df\")\n",
    "metadata_df.to_hdf(os.path.join(data_path, \"metadata_df_with_sim_index_v2_final.h5\"), key=\"metadata_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alireza\\AppData\\Local\\Temp\\ipykernel_12896\\1268087068.py:1: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block3_values] [items->Index(['output_type', 'trget_imge_name', 'similarity_metric', 'gan_name',\n",
      "       'layer_name', 'layer_short', 'net_name', 'img_size', 'pading_size',\n",
      "       'input_size', 'pop_unit_idx', 'sub_pop_type', 'gen_rerun_id',\n",
      "       'data_root'],\n",
      "      dtype='object')]\n",
      "\n",
      "  metadata_df.to_hdf(os.path.join(data_path, \"metadata_df_with_sim_index.h5\"), key=\"metadata_df\")\n"
     ]
    }
   ],
   "source": [
    "metadata_df.to_hdf(os.path.join(data_path, \"metadata_df_with_sim_index.h5\"), key=\"metadata_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_type</th>\n",
       "      <th>trget_imge_name</th>\n",
       "      <th>similarity_metric</th>\n",
       "      <th>pop_size</th>\n",
       "      <th>pop_resampling_id</th>\n",
       "      <th>gan_name</th>\n",
       "      <th>layer_name</th>\n",
       "      <th>layer_short</th>\n",
       "      <th>net_name</th>\n",
       "      <th>img_size</th>\n",
       "      <th>...</th>\n",
       "      <th>data_root</th>\n",
       "      <th>l2_distance</th>\n",
       "      <th>alexnet</th>\n",
       "      <th>vgg16</th>\n",
       "      <th>resnet50</th>\n",
       "      <th>resnet101</th>\n",
       "      <th>pixel_dist_normalized</th>\n",
       "      <th>sim_index</th>\n",
       "      <th>sim_index_l1</th>\n",
       "      <th>sim_index_l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1687416128_4419577</th>\n",
       "      <td>target_img</td>\n",
       "      <td>imagenet_18</td>\n",
       "      <td>None</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>fc6</td>\n",
       "      <td>.features.Conv2d3</td>\n",
       "      <td>conv2</td>\n",
       "      <td>alexnet</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>N:\\PonceLab\\Users\\Alireza\\insilico_experiments...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687416128_4445313</th>\n",
       "      <td>target_img_RF_masked</td>\n",
       "      <td>imagenet_18</td>\n",
       "      <td>None</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>fc6</td>\n",
       "      <td>.features.Conv2d3</td>\n",
       "      <td>conv2</td>\n",
       "      <td>alexnet</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>N:\\PonceLab\\Users\\Alireza\\insilico_experiments...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687416147_5999399</th>\n",
       "      <td>best_gen_imgs</td>\n",
       "      <td>imagenet_18</td>\n",
       "      <td>cosine</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>fc6</td>\n",
       "      <td>.features.Conv2d3</td>\n",
       "      <td>conv2</td>\n",
       "      <td>alexnet</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>N:\\PonceLab\\Users\\Alireza\\insilico_experiments...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687416147_8799687</th>\n",
       "      <td>best_gen_imgs_RF_masked</td>\n",
       "      <td>imagenet_18</td>\n",
       "      <td>cosine</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>fc6</td>\n",
       "      <td>.features.Conv2d3</td>\n",
       "      <td>conv2</td>\n",
       "      <td>alexnet</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>N:\\PonceLab\\Users\\Alireza\\insilico_experiments...</td>\n",
       "      <td>8.271968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700716</td>\n",
       "      <td>0.656972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687416147_6061125</th>\n",
       "      <td>last_gen_mean_imgs</td>\n",
       "      <td>imagenet_18</td>\n",
       "      <td>cosine</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>fc6</td>\n",
       "      <td>.features.Conv2d3</td>\n",
       "      <td>conv2</td>\n",
       "      <td>alexnet</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>N:\\PonceLab\\Users\\Alireza\\insilico_experiments...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                output_type trget_imge_name similarity_metric   \n",
       "1687416128_4419577               target_img     imagenet_18              None  \\\n",
       "1687416128_4445313     target_img_RF_masked     imagenet_18              None   \n",
       "1687416147_5999399            best_gen_imgs     imagenet_18            cosine   \n",
       "1687416147_8799687  best_gen_imgs_RF_masked     imagenet_18            cosine   \n",
       "1687416147_6061125       last_gen_mean_imgs     imagenet_18            cosine   \n",
       "\n",
       "                    pop_size  pop_resampling_id gan_name         layer_name   \n",
       "1687416128_4419577       128                  0      fc6  .features.Conv2d3  \\\n",
       "1687416128_4445313       128                  0      fc6  .features.Conv2d3   \n",
       "1687416147_5999399       128                  0      fc6  .features.Conv2d3   \n",
       "1687416147_8799687       128                  0      fc6  .features.Conv2d3   \n",
       "1687416147_6061125       128                  0      fc6  .features.Conv2d3   \n",
       "\n",
       "                   layer_short net_name img_size  ...   \n",
       "1687416128_4419577       conv2  alexnet     None  ...  \\\n",
       "1687416128_4445313       conv2  alexnet     None  ...   \n",
       "1687416147_5999399       conv2  alexnet     None  ...   \n",
       "1687416147_8799687       conv2  alexnet     None  ...   \n",
       "1687416147_6061125       conv2  alexnet     None  ...   \n",
       "\n",
       "                                                            data_root   \n",
       "1687416128_4419577  N:\\PonceLab\\Users\\Alireza\\insilico_experiments...  \\\n",
       "1687416128_4445313  N:\\PonceLab\\Users\\Alireza\\insilico_experiments...   \n",
       "1687416147_5999399  N:\\PonceLab\\Users\\Alireza\\insilico_experiments...   \n",
       "1687416147_8799687  N:\\PonceLab\\Users\\Alireza\\insilico_experiments...   \n",
       "1687416147_6061125  N:\\PonceLab\\Users\\Alireza\\insilico_experiments...   \n",
       "\n",
       "                   l2_distance  alexnet vgg16 resnet50 resnet101   \n",
       "1687416128_4419577         NaN      NaN   NaN      NaN       NaN  \\\n",
       "1687416128_4445313         NaN      NaN   NaN      NaN       NaN   \n",
       "1687416147_5999399         NaN      NaN   NaN      NaN       NaN   \n",
       "1687416147_8799687    8.271968      NaN   NaN      NaN       NaN   \n",
       "1687416147_6061125         NaN      NaN   NaN      NaN       NaN   \n",
       "\n",
       "                   pixel_dist_normalized  sim_index  sim_index_l1   \n",
       "1687416128_4419577                   NaN        NaN           NaN  \\\n",
       "1687416128_4445313                   NaN        NaN           NaN   \n",
       "1687416147_5999399                   NaN        NaN           NaN   \n",
       "1687416147_8799687              0.540106        NaN      0.700716   \n",
       "1687416147_6061125                   NaN        NaN           NaN   \n",
       "\n",
       "                    sim_index_l2  \n",
       "1687416128_4419577           NaN  \n",
       "1687416128_4445313           NaN  \n",
       "1687416147_5999399           NaN  \n",
       "1687416147_8799687      0.656972  \n",
       "1687416147_6061125           NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosine-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
