{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nwb-dev/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import pytubefix\n",
    "import os\n",
    "\n",
    "os.environ[\"IMAGEIO_FFMPEG_EXE\"] = \"/opt/anaconda3/envs/ponce/lib/python3.13/site-packages/imageio_ffmpeg/binaries/ffmpeg\"\n",
    "\n",
    "#import moviepy.editor as mp\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from core.utils.func_lib import *\n",
    "from core.utils.GAN_utils import upconvGAN\n",
    "from core.utils.GAN_utils import loadBigGAN, BigGAN_wrapper\n",
    "from core.utils.GAN_invert_utils import *\n",
    "from core.utils.GAN_utils import upconvGAN\n",
    "\n",
    "from scipy.stats import special_ortho_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.youtube.com/watch?v=ND92YNQv0TU macaque_running 54.0 56.0\n",
      "clipped\n",
      "Moviepy - Building video /Users/dysprague/Ponce_rotation/data/videos_cropped/macaque_running.mp4.\n",
      "Moviepy - Writing video /Users/dysprague/Ponce_rotation/data/videos_cropped/macaque_running.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/dysprague/Ponce_rotation/data/videos_cropped/macaque_running.mp4\n",
      "saved\n",
      "Cropped video saved as macaque_running\n",
      "https://www.youtube.com/watch?v=mPrVMX8ACSE macaque_eating 62.0 64.0\n",
      "clipped\n",
      "Moviepy - Building video /Users/dysprague/Ponce_rotation/data/videos_cropped/macaque_eating.mp4.\n",
      "Moviepy - Writing video /Users/dysprague/Ponce_rotation/data/videos_cropped/macaque_eating.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/dysprague/Ponce_rotation/data/videos_cropped/macaque_eating.mp4\n",
      "saved\n",
      "Cropped video saved as macaque_eating\n",
      "https://www.youtube.com/watch?v=IEq5flqW8FE monkey_grooming 240.0 242.0\n",
      "clipped\n",
      "Moviepy - Building video /Users/dysprague/Ponce_rotation/data/videos_cropped/monkey_grooming.mp4.\n",
      "Moviepy - Writing video /Users/dysprague/Ponce_rotation/data/videos_cropped/monkey_grooming.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/dysprague/Ponce_rotation/data/videos_cropped/monkey_grooming.mp4\n",
      "saved\n",
      "Cropped video saved as monkey_grooming\n",
      "https://www.youtube.com/watch?v=641EOJCk8p8 monkey_fighting 143.0 145.0\n",
      "clipped\n",
      "Moviepy - Building video /Users/dysprague/Ponce_rotation/data/videos_cropped/monkey_fighting.mp4.\n",
      "Moviepy - Writing video /Users/dysprague/Ponce_rotation/data/videos_cropped/monkey_fighting.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/dysprague/Ponce_rotation/data/videos_cropped/monkey_fighting.mp4\n",
      "saved\n",
      "Cropped video saved as monkey_fighting\n",
      "https://www.youtube.com/watch?v=7utuuiw7v0U cats_jumping 11.0 13.0\n",
      "clipped\n",
      "Moviepy - Building video /Users/dysprague/Ponce_rotation/data/videos_cropped/cats_jumping.mp4.\n",
      "Moviepy - Writing video /Users/dysprague/Ponce_rotation/data/videos_cropped/cats_jumping.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/dysprague/Ponce_rotation/data/videos_cropped/cats_jumping.mp4\n",
      "saved\n",
      "Cropped video saved as cats_jumping\n",
      "https://www.youtube.com/watch?v=28FzV5OHqMU komodo 57.0 59.0\n",
      "clipped\n",
      "Moviepy - Building video /Users/dysprague/Ponce_rotation/data/videos_cropped/komodo.mp4.\n",
      "Moviepy - Writing video /Users/dysprague/Ponce_rotation/data/videos_cropped/komodo.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/dysprague/Ponce_rotation/data/videos_cropped/komodo.mp4\n",
      "saved\n",
      "Cropped video saved as komodo\n",
      "https://www.youtube.com/watch?v=p6CFBpe8zws horses 28.0 30.0\n",
      "clipped\n",
      "Moviepy - Building video /Users/dysprague/Ponce_rotation/data/videos_cropped/horses.mp4.\n",
      "Moviepy - Writing video /Users/dysprague/Ponce_rotation/data/videos_cropped/horses.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/dysprague/Ponce_rotation/data/videos_cropped/horses.mp4\n",
      "saved\n",
      "Cropped video saved as horses\n",
      "https://www.youtube.com/watch?v=xUmU_mVH_34 ambulance 40.0 42.0\n",
      "clipped\n",
      "Moviepy - Building video /Users/dysprague/Ponce_rotation/data/videos_cropped/ambulance.mp4.\n",
      "Moviepy - Writing video /Users/dysprague/Ponce_rotation/data/videos_cropped/ambulance.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/dysprague/Ponce_rotation/data/videos_cropped/ambulance.mp4\n",
      "saved\n",
      "Cropped video saved as ambulance\n",
      "https://www.youtube.com/watch?v=_D6Zi9OlUVM fan 17.0 19.0\n",
      "clipped\n",
      "Moviepy - Building video /Users/dysprague/Ponce_rotation/data/videos_cropped/fan.mp4.\n",
      "Moviepy - Writing video /Users/dysprague/Ponce_rotation/data/videos_cropped/fan.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/dysprague/Ponce_rotation/data/videos_cropped/fan.mp4\n",
      "saved\n",
      "Cropped video saved as fan\n",
      "https://www.youtube.com/watch?v=pjJBVjXhFRU soccer_ball 25.0 27.0\n",
      "clipped\n",
      "Moviepy - Building video /Users/dysprague/Ponce_rotation/data/videos_cropped/soccer_ball.mp4.\n",
      "Moviepy - Writing video /Users/dysprague/Ponce_rotation/data/videos_cropped/soccer_ball.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/dysprague/Ponce_rotation/data/videos_cropped/soccer_ball.mp4\n",
      "saved\n",
      "Cropped video saved as soccer_ball\n",
      "nan nan nan nan\n",
      "Error processing video nan: unsupported operand type(s) for +: 'float' and 'str'\n",
      "nan nan nan nan\n",
      "Error processing video nan: unsupported operand type(s) for +: 'float' and 'str'\n",
      "nan nan nan nan\n",
      "Error processing video nan: unsupported operand type(s) for +: 'float' and 'str'\n",
      "nan nan nan nan\n",
      "Error processing video nan: unsupported operand type(s) for +: 'float' and 'str'\n"
     ]
    }
   ],
   "source": [
    "def download_youtube_videos(inp_csv_file, output_videos, resolution='720p', bitrate='8M'):\n",
    "\n",
    "    vids_df = pd.read_csv(inp_csv_file)\n",
    "    links, file_names = vids_df['video'].values, vids_df['video_name'].values\n",
    "    starts, ends = vids_df['start'].values, vids_df['end'].values\n",
    "\n",
    "    for link, file_name, start, end in zip(links, file_names, starts, ends):\n",
    "        try:\n",
    "            print(link, file_name, start, end)\n",
    "            youtube = pytubefix.YouTube(link)\n",
    "            video = youtube.streams.filter(res=resolution).first()\n",
    "            video.download(output_path = output_videos)\n",
    "            filename = video.default_filename\n",
    "\n",
    "            os.rename(os.path.join(output_videos,filename), os.path.join(output_videos, file_name+'.mp4'))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing video {link}: {e}\")\n",
    "\n",
    "def crop_videos(inp_csv_file, input_videos, output_cropped, bitrate= '8M'):\n",
    "    vids_df = pd.read_csv(inp_csv_file)\n",
    "    links, file_names = vids_df['video'].values, vids_df['video_name'].values\n",
    "    starts, ends = vids_df['start'].values, vids_df['end'].values\n",
    "\n",
    "    for link, file_name, start, end in zip(links, file_names, starts, ends):\n",
    "        try:\n",
    "            print(link, file_name, start, end)\n",
    "            video_clip = mp.VideoFileClip(os.path.join(input_videos,file_name +'.mp4')).subclip(start, end)\n",
    "            output_path = os.path.join(output_cropped, f\"{file_name}.mp4\")\n",
    "            print('clipped')\n",
    "            video_clip.write_videofile(output_path, fps=video_clip.fps, audio=False)\n",
    "            print('saved')\n",
    "            print(f\"Cropped video saved as {file_name}\")\n",
    "            video_clip.close()\n",
    "            #os.remove(filename)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing video {link}: {e}\")\n",
    "\n",
    "\n",
    "inp_csv_file = \"/Users/dysprague/Ponce_rotation/data/videos.csv\"\n",
    "output_video = \"/Users/dysprague/Ponce_rotation/data/videos\"\n",
    "output_cropped = \"/Users/dysprague/Ponce_rotation/data/videos_trimmed\"\n",
    "\n",
    "#download_youtube_videos(inp_csv_file, output_video)\n",
    "\n",
    "crop_videos(inp_csv_file, output_video, output_cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate videos into component frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/dysprague/Ponce_rotation/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file in os.listdir(os.path.join(data_dir, 'videos_trimmed')):\n",
    "    if not file[-4:] == '.mp4':\n",
    "        continue\n",
    "\n",
    "    frameNr = 0\n",
    "\n",
    "    capture = cv2.VideoCapture(os.path.join(data_dir, 'videos_trimmed', file))\n",
    " \n",
    "    while (True):\n",
    "    \n",
    "        success, frame = capture.read()\n",
    "\n",
    "        if not os.path.exists(os.path.join(data_dir, 'video_frames', file[:-4])):\n",
    "            os.makedirs(os.path.join(data_dir, 'video_frames', file[:-4]))\n",
    "    \n",
    "        if success:\n",
    "            cv2.imwrite(f'{data_dir}/video_frames/{file[:-4]}/frame_{frameNr}.jpg', frame)\n",
    "    \n",
    "        else:\n",
    "            break\n",
    "    \n",
    "        frameNr = frameNr+1\n",
    "    \n",
    "    capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert inverted frames back to videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "for folder in os.listdir(os.path.join(data_dir, 'videos_random_gen')):\n",
    "    if folder == '.DS_Store':\n",
    "        continue\n",
    "    img_folder = os.path.join(data_dir, 'videos_random_gen', folder)\n",
    "    video_name = folder + '.mp4'\n",
    "\n",
    "    frames = int(len(os.listdir(img_folder))/2)\n",
    "\n",
    "    images = [f'frame_{i}_inv.png' for i in range(frames)]\n",
    "\n",
    "    #images = [img for img in os.listdir(img_folder) if img.endswith(\"inverted.png\")]\n",
    "    frame = cv2.imread(os.path.join(img_folder, images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(video_name, fourcc, len(images)/2, (width,height))\n",
    "\n",
    "    for image in images:\n",
    "        video.write(cv2.imread(os.path.join(img_folder, image)))\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frame_0_inverted.png', 'frame_1_inverted.png', 'frame_2_inverted.png', 'frame_3_inverted.png', 'frame_4_inverted.png', 'frame_5_inverted.png', 'frame_6_inverted.png', 'frame_7_inverted.png', 'frame_8_inverted.png', 'frame_9_inverted.png', 'frame_10_inverted.png', 'frame_11_inverted.png', 'frame_12_inverted.png', 'frame_13_inverted.png', 'frame_14_inverted.png', 'frame_15_inverted.png', 'frame_16_inverted.png', 'frame_17_inverted.png', 'frame_18_inverted.png', 'frame_19_inverted.png', 'frame_20_inverted.png', 'frame_21_inverted.png', 'frame_22_inverted.png', 'frame_23_inverted.png', 'frame_24_inverted.png', 'frame_25_inverted.png', 'frame_26_inverted.png', 'frame_27_inverted.png', 'frame_28_inverted.png', 'frame_29_inverted.png', 'frame_30_inverted.png', 'frame_31_inverted.png', 'frame_32_inverted.png', 'frame_33_inverted.png', 'frame_34_inverted.png', 'frame_35_inverted.png', 'frame_36_inverted.png', 'frame_37_inverted.png', 'frame_38_inverted.png', 'frame_39_inverted.png', 'frame_40_inverted.png', 'frame_41_inverted.png', 'frame_42_inverted.png', 'frame_43_inverted.png', 'frame_44_inverted.png', 'frame_45_inverted.png', 'frame_46_inverted.png', 'frame_47_inverted.png', 'frame_48_inverted.png', 'frame_49_inverted.png', 'frame_50_inverted.png', 'frame_51_inverted.png', 'frame_52_inverted.png', 'frame_53_inverted.png', 'frame_54_inverted.png', 'frame_55_inverted.png', 'frame_56_inverted.png', 'frame_57_inverted.png', 'frame_58_inverted.png', 'frame_59_inverted.png']\n"
     ]
    }
   ],
   "source": [
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_data = {}\n",
    "total_samples = None\n",
    "\n",
    "for folder in os.listdir(os.path.join(data_dir, 'videos_inverted')):\n",
    "    if folder == '.DS_Store':\n",
    "        continue\n",
    "    \n",
    "    img_folder = os.path.join(data_dir, 'videos_inverted', folder)\n",
    "    frames = int(len(os.listdir(img_folder))/3)\n",
    "\n",
    "    for i in range(frames):\n",
    "        code = np.load(os.path.join(img_folder,f'frame_{i}_code.npy'))\n",
    "\n",
    "        if not folder in videos_data.keys():\n",
    "            videos_data[folder] = np.asarray([code])\n",
    "        else:\n",
    "            videos_data[folder] = np.vstack((videos_data[folder], code))\n",
    "\n",
    "        if total_samples is None:\n",
    "            total_samples = np.asarray([code])\n",
    "        else:\n",
    "            total_samples = np.vstack((total_samples, code))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(666, 4096)\n",
      "[(60, 4096), (48, 4096), (50, 4096), (120, 4096), (50, 4096), (120, 4096), (50, 4096), (60, 4096), (48, 4096), (60, 4096)]\n"
     ]
    }
   ],
   "source": [
    "print(total_samples.shape)\n",
    "print([value.shape for value in videos_data.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(60, 4096), (48, 4096), (50, 4096), (120, 4096), (50, 4096), (120, 4096), (50, 4096), (60, 4096), (48, 4096), (60, 4096)]\n"
     ]
    }
   ],
   "source": [
    "print([value.shape for value in videos_data.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig = plt.figure()\n",
    "\n",
    "for key, value in videos_data.items():\n",
    "    diff = [np.linalg.norm(value[i+1,:]-value[i,:])/value.shape[1] for i in range(value.shape[0]-1)]\n",
    "\n",
    "    plt.plot(np.linspace(0,2,len(diff)),diff, label=key)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('time (seconds)')\n",
    "plt.ylabel('Time derivative in encoded space')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for key, value in videos_data.items():\n",
    "    theta = [np.arccos(np.dot(value[i+1,:] - value[i,:], value[i,:]-value[i-1,:])/(np.linalg.norm(value[i+1,:] - value[i,:])* np.linalg.norm(value[i,:] - value[i-1,:]))) for i in range(1,value.shape[0]-1)]\n",
    "\n",
    "    plt.plot(np.linspace(0,2,len(theta)),theta, label=key)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('time (seconds)')\n",
    "plt.ylabel('Angle between directions of subsequent frames in encoding space')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for key, value in videos_data.items():\n",
    "    diff = [np.linalg.norm(value[i,:]-value[0,:])/value.shape[1] for i in range(value.shape[0])]\n",
    "\n",
    "    plt.plot(np.linspace(0,2,len(diff)),diff, label=key)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('time (seconds)')\n",
    "plt.ylabel('distance from original frame in encoded space')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "\n",
    "pca = pca.fit(total_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_code = {} \n",
    "\n",
    "for key, value in videos_data.items():\n",
    "\n",
    "    reduced = pca.transform(value)\n",
    "\n",
    "    pca_code[key] = reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(60, 666), (48, 666), (50, 666), (120, 666), (50, 666), (120, 666), (50, 666), (60, 666), (48, 666), (60, 666)]\n"
     ]
    }
   ],
   "source": [
    "print([value.shape for value in pca_code.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5)\n",
    "\n",
    "code = pca_code['soccer_ball']\n",
    "\n",
    "n_points = code.shape[0]\n",
    "\n",
    "colors = cm.viridis(np.linspace(0,1,n_points))\n",
    "\n",
    "for j in range(n_points-1):\n",
    "    axs[0].scatter(code[j,0], code[j,1], color=colors[j])\n",
    "    axs[1].scatter(code[j,2], code[j,3], color=colors[j])\n",
    "    axs[2].scatter(code[j,4], code[j,5], color=colors[j])\n",
    "    axs[3].scatter(code[j,6], code[j,7], color=colors[j])\n",
    "    axs[4].scatter(code[j,8], code[j,9], color=colors[j])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for key, value in pca_code.items():\n",
    "\n",
    "    plt.scatter(value[:,0], value[:,1], label=key)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('PC_dimension 1')\n",
    "plt.ylabel('PC_dimension 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for key, value in pca_code.items():\n",
    "\n",
    "    plt.scatter(value[:,2], value[:,3], label=key)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('PC_dimension 3')\n",
    "plt.ylabel('PC_dimension 4')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cached device pixel ratio value was stale on window expose.  Please file a QTBUG which explains how to reproduce.\n",
      "The cached device pixel ratio value was stale on window expose.  Please file a QTBUG which explains how to reproduce.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for key, value in pca_code.items():\n",
    "\n",
    "    plt.scatter(value[:,4], value[:,5], label=key)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('PC_dimension 5')\n",
    "plt.ylabel('PC_dimension 6')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA on 750 inverted image net images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/dysprague/Ponce_rotation/data'\n",
    "test_samples = None\n",
    "\n",
    "for file in os.listdir(os.path.join(data_dir, 'imagenet_test_inverted')):\n",
    "    if not file[-4:] == '.npy':\n",
    "        continue\n",
    "    \n",
    "    code  = np.load(os.path.join(data_dir, 'imagenet_test_inverted', file))\n",
    "\n",
    "    if test_samples is None:\n",
    "        test_samples = np.asarray([code])\n",
    "    else:\n",
    "        test_samples = np.vstack((test_samples, code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "\n",
    "pca = pca.fit(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = pca.transform(total_samples)\n",
    "pca_code = {} \n",
    "\n",
    "for key, value in videos_data.items():\n",
    "\n",
    "    reduced = pca.transform(value)\n",
    "\n",
    "    pca_code[key] = reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(603, 4096)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues = pca.explained_variance_\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.plot(np.cumsum(eigenvalues)/np.sum(eigenvalues))\n",
    "\n",
    "#plt.xscale('log')\n",
    "\n",
    "plt.xlabel('#PC dimensions used')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt \n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for key, value in pca_code.items():\n",
    "\n",
    "    plt.scatter(value[:,0], value[:,1], label=key)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('PC_dimension 1')\n",
    "plt.ylabel('PC_dimension 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9t/68zflby9385dfmd93cm_b7ph0000gn/T/ipykernel_44666/3007476109.py:9: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend()\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt \n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "full_pca = pca.transform(test_samples)\n",
    "\n",
    "plt.scatter(full_pca[:,0], full_pca[:,1])\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('PC_dimension 1')\n",
    "plt.ylabel('PC_dimension 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 603)\n"
     ]
    }
   ],
   "source": [
    "print(pca_code['macaque_eating'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "\n",
    "x_train = None \n",
    "y_train = None\n",
    "\n",
    "for key, value in pca_code.items():\n",
    "    if x_train is None:\n",
    "        x_train = value \n",
    "        y_train = np.expand_dims(np.asarray([key for i in range(value.shape[0])]), axis=1)\n",
    "        \n",
    "\n",
    "    else:\n",
    "        x_train = np.vstack((x_train, value))\n",
    "        y_train = np.vstack((y_train, np.expand_dims(np.asarray([key for i in range(value.shape[0])]), axis=1)))\n",
    "\n",
    "y_train = np.squeeze(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(666,)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = np.zeros(x_train.shape[1]-1)\n",
    "\n",
    "for i in range(1,len(accs)):\n",
    "    svm_model_linear = SVC(kernel = 'linear', C = 1).fit(x_train[:,:i], y_train) \n",
    "    \n",
    "    # model accuracy for X_test   \n",
    "    accs[i] = svm_model_linear.score(x_train[:,:i], y_train) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = np.zeros(x_train.shape[1]-1)\n",
    "\n",
    "for i in range(1,len(accs)):\n",
    "    svm_model_linear = SVC(kernel = 'linear', C = 1).fit(x_train[:300,:i], y_train[:300]) \n",
    "    \n",
    "    # model accuracy for X_test   \n",
    "    accs[i] = svm_model_linear.score(x_train[:300,:i], y_train[:300]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() \n",
    "\n",
    "plt.plot(accs)\n",
    "plt.xlabel('#PC dimensions used')\n",
    "plt.ylabel('Accuracy of linear classification')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[183], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m code \u001b[38;5;241m=\u001b[39m pca_code[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mambulance\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m n_points \u001b[38;5;241m=\u001b[39m code\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m colors \u001b[38;5;241m=\u001b[39m cm\u001b[38;5;241m.\u001b[39mviridis(np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,n_points))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_points\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     10\u001b[0m     axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mscatter(code[j,\u001b[38;5;241m0\u001b[39m], code[j,\u001b[38;5;241m1\u001b[39m], color\u001b[38;5;241m=\u001b[39mcolors[j])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(5)\n",
    "\n",
    "code = pca_code['ambulance']\n",
    "\n",
    "n_points = code.shape[0]\n",
    "\n",
    "colors = cm.viridis(np.linspace(0,1,n_points))\n",
    "\n",
    "for j in range(n_points-1):\n",
    "    axs[0].scatter(code[j,0], code[j,1], color=colors[j])\n",
    "    axs[1].scatter(code[j,2], code[j,3], color=colors[j])\n",
    "    axs[2].scatter(code[j,4], code[j,5], color=colors[j])\n",
    "    axs[3].scatter(code[j,6], code[j,7], color=colors[j])\n",
    "    axs[4].scatter(code[j,8], code[j,9], color=colors[j])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import special_ortho_group\n",
    "num_dim=60\n",
    "x = special_ortho_group.rvs(num_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturb image invert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "invert_path = '/Users/dysprague/Ponce_rotation/data/videos_inverted'\n",
    "\n",
    "codes = {}\n",
    "\n",
    "for folder in os.listdir(invert_path):\n",
    "    if folder == '.DS_Store':\n",
    "        continue\n",
    "\n",
    "    img_folder = os.path.join(invert_path, folder)\n",
    "    frames = int(len(os.listdir(img_folder))/3)\n",
    "\n",
    "    for i in range(frames):\n",
    "        code = np.load(os.path.join(img_folder,f'frame_{i}_code.npy')) \n",
    "\n",
    "        if not folder in codes.keys():\n",
    "            codes[folder] = np.asarray([code])\n",
    "        else:\n",
    "            codes[folder] = np.vstack((codes[folder], code))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate = special_ortho_group.rvs(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_code = {}\n",
    "noise_code = {} \n",
    "reverse_code = {} \n",
    "check_code = {} \n",
    "\n",
    "for key, value in codes.items():\n",
    "    \n",
    "    centered_code = value - np.ones((value.shape[0],1)) @ value[0].reshape(-1,1).transpose()\n",
    "\n",
    "    r_use = rotate\n",
    "\n",
    "    np.random.shuffle(r_use) \n",
    "\n",
    "    rotation_matrix = r_use\n",
    "\n",
    "    rotated_code = (rotation_matrix @ centered_code.transpose()).transpose()\n",
    "\n",
    "    uncentered_rotated = rotated_code + np.ones((value.shape[0],1)) @ value[0].reshape(-1,1).transpose()\n",
    "\n",
    "    rotate_code[key] = uncentered_rotated \n",
    "\n",
    "    check_code[key] = value[0,:].reshape(-1,1).transpose()\n",
    "    reverse_code[key] = value[0,:].reshape(-1,1).transpose()\n",
    "    noise_code[key] = value[0,:].reshape(-1,1).transpose()\n",
    "\n",
    "    for i in range(1,value.shape[0]):\n",
    "\n",
    "        diff = np.squeeze(value[i,:]) - np.squeeze(value[i-1,:])\n",
    "\n",
    "        control = np.squeeze(value[i-1,:]) + diff \n",
    "\n",
    "        reverse = np.squeeze(reverse_code[key][i-1,:]) - diff \n",
    "\n",
    "        noise = np.random.normal(0, 0.2, diff.shape)\n",
    "\n",
    "        noisy_update = np.squeeze(noise_code[key][i-1,:]) + noise\n",
    "\n",
    "        check_code[key] = np.vstack((check_code[key], control.reshape(-1,1).transpose()))\n",
    "        reverse_code[key] = np.vstack((reverse_code[key], reverse.reshape(-1,1).transpose()))\n",
    "        noise_code[key] = np.vstack((noise_code[key], noisy_update.reshape(-1,1).transpose()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dysprague/Ponce_rotation/core/utils/GAN_utils.py:179: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  SD = torch.load(savepath[name])\n"
     ]
    }
   ],
   "source": [
    "G = upconvGAN('fc6').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/Users/dysprague/Ponce_rotation/data/images_perturbed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023.5905\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in codes.keys():\n",
    "    check = check_code[key]\n",
    "    reverse = reverse_code[key]\n",
    "    noise = noise_code[key]\n",
    "    rot = rotate_code[key]\n",
    "\n",
    "    for i in range(check.shape[0]):\n",
    "\n",
    "        os.makedirs(os.path.join(save_dir, 'control', key), exist_ok=True)\n",
    "        os.makedirs(os.path.join(save_dir, 'noise', key), exist_ok=True)\n",
    "        os.makedirs(os.path.join(save_dir, 'reverse', key), exist_ok=True)\n",
    "        os.makedirs(os.path.join(save_dir, 'rotation', key), exist_ok=True)\n",
    "\n",
    "        noise_im = torch.tensor(noise[i,:]).float()\n",
    "        img_noise = G.visualize(noise_im.detach())\n",
    "        img_noise_save = ToPILImage()(np.squeeze(img_noise))\n",
    "        img_noise_save.save(os.path.join(save_dir, 'noise', key, f\"frame_{i}_inverted.png\"))\n",
    "        np.save(os.path.join(save_dir, 'noise', key, f\"frame_{i}_code.npy\"), arr= noise_im )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in codes.keys():\n",
    "    check = check_code[key]\n",
    "    reverse = reverse_code[key]\n",
    "    noise = noise_code[key]\n",
    "    rot = rotate_code[key]\n",
    "\n",
    "    for i in range(check.shape[0]):\n",
    "\n",
    "        os.makedirs(os.path.join(save_dir, 'control', key), exist_ok=True)\n",
    "        os.makedirs(os.path.join(save_dir, 'noise', key), exist_ok=True)\n",
    "        os.makedirs(os.path.join(save_dir, 'reverse', key), exist_ok=True)\n",
    "        os.makedirs(os.path.join(save_dir, 'rotation', key), exist_ok=True)\n",
    "\n",
    "        check_im = torch.tensor(check[i,:]).float()\n",
    "        img_check = G.visualize(check_im.detach())\n",
    "        img_check_save = ToPILImage()(np.squeeze(img_check))\n",
    "        img_check_save.save(os.path.join(save_dir, 'control', key, f\"frame_{i}_inverted.png\"))\n",
    "        np.save(os.path.join(save_dir, 'control', key, f\"frame_{i}_code.npy\"), arr=check_im)\n",
    "\n",
    "        reverse_im = torch.tensor(reverse[i,:]).float()\n",
    "        img_reverse = G.visualize(reverse_im.detach())\n",
    "        img_reverse_save = ToPILImage()(np.squeeze(img_reverse))\n",
    "        img_reverse_save.save(os.path.join(save_dir, 'reverse', key, f\"frame_{i}_inverted.png\"))\n",
    "        np.save(os.path.join(save_dir, 'reverse', key, f\"frame_{i}_code.npy\"), arr= reverse_im )\n",
    "\n",
    "        noise_im = torch.tensor(noise[i,:]).float()\n",
    "        img_noise = G.visualize(noise_im.detach())\n",
    "        img_noise_save = ToPILImage()(np.squeeze(img_noise))\n",
    "        img_noise_save.save(os.path.join(save_dir, 'noise', key, f\"frame_{i}_inverted.png\"))\n",
    "        np.save(os.path.join(save_dir, 'noise', key, f\"frame_{i}_code.npy\"), arr= noise_im )\n",
    "\n",
    "        rot_im = torch.tensor(rot[i,:]).float()\n",
    "        img_rot = G.visualize(rot_im.detach())\n",
    "        img_rot_save = ToPILImage()(np.squeeze(img_rot))\n",
    "        img_rot_save.save(os.path.join(save_dir, 'rotation', key, f\"frame_{i}_inverted.png\"))\n",
    "        np.save(os.path.join(save_dir, 'rotation', key, f\"frame_{i}_code.npy\"), arr= rot_im )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "for folder in os.listdir(os.path.join(save_dir)):\n",
    "    if folder == '.DS_Store':\n",
    "        continue\n",
    "\n",
    "    for img_folder in os.listdir(os.path.join(save_dir,folder)):\n",
    "        if img_folder =='.DS_Store':\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(save_dir, folder, img_folder)\n",
    "        video_name = os.path.join(save_dir, '..', 'videos_perturbed', folder, img_folder) + '.mp4'\n",
    "\n",
    "        frames = int(len(os.listdir(img_path))/2)\n",
    "\n",
    "        images = [f'frame_{i}_inverted.png' for i in range(frames)]\n",
    "\n",
    "        #images = [img for img in os.listdir(img_folder) if img.endswith(\"inverted.png\")]\n",
    "        frame = cv2.imread(os.path.join(img_path, images[0]))\n",
    "        height, width, layers = frame.shape\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        video = cv2.VideoWriter(video_name, fourcc, len(images)/2, (width,height))\n",
    "\n",
    "        for image in images:\n",
    "            video.write(cv2.imread(os.path.join(img_path, image)))\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "        video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test different titrations of reversal and rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import expm, logm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_scaling_factor = 0.5\n",
    "scaling_factor = 0.1\n",
    "noise_factor = 0.5\n",
    "\n",
    "r_use = rotate \n",
    "\n",
    "rotation_matrix = r_use\n",
    "\n",
    "log_rotation_matrix = logm(rotation_matrix)\n",
    "\n",
    "scaled_log_rotation_matrix = rotation_scaling_factor * log_rotation_matrix\n",
    "\n",
    "scaled_rotation_matrix = expm(scaled_log_rotation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_code = {}\n",
    "reverse_code = {} \n",
    "check_code = {} \n",
    "noise_code = {}\n",
    "\n",
    "for key, value in codes.items():\n",
    "    \n",
    "    centered_code = value - np.ones((value.shape[0],1)) @ value[0].reshape(-1,1).transpose()\n",
    "\n",
    "    rotated_code = (scaled_rotation_matrix @ centered_code.transpose()).transpose()\n",
    "\n",
    "    uncentered_rotated = rotated_code + np.ones((value.shape[0],1)) @ value[0].reshape(-1,1).transpose()\n",
    "\n",
    "    rotate_code[key] = uncentered_rotated \n",
    "\n",
    "    check_code[key] = value[0,:].reshape(-1,1).transpose()\n",
    "    reverse_code[key] = value[0,:].reshape(-1,1).transpose()\n",
    "    noise_code[key] = value[0,:].reshape(-1,1).transpose()\n",
    "\n",
    "    for i in range(1,value.shape[0]):\n",
    "\n",
    "        diff = np.squeeze(value[i,:]) - np.squeeze(value[i-1,:])\n",
    "\n",
    "        control = np.squeeze(check_code[key][i-1,:]) + diff*scaling_factor\n",
    "\n",
    "        reverse = np.squeeze(reverse_code[key][i-1,:]) - diff*scaling_factor \n",
    "\n",
    "        noise = np.random.normal(0, noise_factor, diff.shape)\n",
    "\n",
    "        noisy_update = np.squeeze(noise_code[key][i-1,:]) + noise\n",
    "\n",
    "        check_code[key] = np.vstack((check_code[key], control.reshape(-1,1).transpose()))\n",
    "        reverse_code[key] = np.vstack((reverse_code[key], reverse.reshape(-1,1).transpose()))\n",
    "        noise_code[key] = np.vstack((noise_code[key], noisy_update.reshape(-1,1).transpose()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/Users/dysprague/Ponce_rotation/data/images_perturbed_test'\n",
    "\n",
    "for key in codes.keys():\n",
    "    check = check_code[key]\n",
    "    reverse = reverse_code[key]\n",
    "    rot = rotate_code[key]\n",
    "    noise = noise_code[key]\n",
    "\n",
    "    for i in range(check.shape[0]):\n",
    "\n",
    "        os.makedirs(os.path.join(save_dir, f'control_{str(scaling_factor)}', key), exist_ok=True)\n",
    "        os.makedirs(os.path.join(save_dir, f'reverse_{str(scaling_factor)}', key), exist_ok=True)\n",
    "        os.makedirs(os.path.join(save_dir, f'rotation_{str(rotation_scaling_factor)}', key), exist_ok=True)\n",
    "        os.makedirs(os.path.join(save_dir, f'noise_{str(noise_factor)}', key), exist_ok=True)\n",
    "\n",
    "        check_im = torch.tensor(check[i,:]).float()\n",
    "        img_check = G.visualize(check_im.detach())\n",
    "        img_check_save = ToPILImage()(np.squeeze(img_check))\n",
    "        img_check_save.save(os.path.join(save_dir, f'control_{str(scaling_factor)}', key, f\"frame_{i}_inverted.png\"))\n",
    "        np.save(os.path.join(save_dir, f'control_{str(scaling_factor)}', key, f\"frame_{i}_code.npy\"), arr=check_im)\n",
    "\n",
    "        reverse_im = torch.tensor(reverse[i,:]).float()\n",
    "        img_reverse = G.visualize(reverse_im.detach())\n",
    "        img_reverse_save = ToPILImage()(np.squeeze(img_reverse))\n",
    "        img_reverse_save.save(os.path.join(save_dir, f'reverse_{str(scaling_factor)}', key, f\"frame_{i}_inverted.png\"))\n",
    "        np.save(os.path.join(save_dir, f'reverse_{str(scaling_factor)}', key, f\"frame_{i}_code.npy\"), arr= reverse_im )\n",
    "\n",
    "        noise_im = torch.tensor(noise[i,:]).float()\n",
    "        img_noise = G.visualize(noise_im.detach())\n",
    "        img_noise_save = ToPILImage()(np.squeeze(img_noise))\n",
    "        img_noise_save.save(os.path.join(save_dir, f'noise_{str(noise_factor)}', key, f\"frame_{i}_inverted.png\"))\n",
    "        np.save(os.path.join(save_dir, f'noise_{str(noise_factor)}', key, f\"frame_{i}_code.npy\"), arr= noise_im )\n",
    "\n",
    "        rot_im = torch.tensor(rot[i,:]).float()\n",
    "        img_rot = G.visualize(rot_im.detach())\n",
    "        img_rot_save = ToPILImage()(np.squeeze(img_rot))\n",
    "        img_rot_save.save(os.path.join(save_dir, f'rotation_{str(rotation_scaling_factor)}', key, f\"frame_{i}_inverted.png\"))\n",
    "        np.save(os.path.join(save_dir, f'rotation_{str(rotation_scaling_factor)}', key, f\"frame_{i}_code.npy\"), arr= rot_im )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in os.listdir(os.path.join(save_dir)):\n",
    "    if folder == '.DS_Store':\n",
    "        continue\n",
    "\n",
    "    for img_folder in os.listdir(os.path.join(save_dir,folder)):\n",
    "        if img_folder =='.DS_Store':\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(save_dir, folder, img_folder)\n",
    "        os.makedirs(os.path.join(save_dir, '..', 'videos_perturbed_test', folder), exist_ok=True)\n",
    "        video_name = os.path.join(save_dir, '..', 'videos_perturbed_test', folder, img_folder) + '.mp4'\n",
    "\n",
    "        frames = int(len(os.listdir(img_path))/2)\n",
    "\n",
    "        images = [f'frame_{i}_inverted.png' for i in range(frames)]\n",
    "\n",
    "        #images = [img for img in os.listdir(img_folder) if img.endswith(\"inverted.png\")]\n",
    "        frame = cv2.imread(os.path.join(img_path, images[0]))\n",
    "        height, width, layers = frame.shape\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        video = cv2.VideoWriter(video_name, fourcc, len(images)/2, (width,height))\n",
    "\n",
    "        for image in images:\n",
    "            video.write(cv2.imread(os.path.join(img_path, image)))\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "        video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print([i*0.1 for i in range(1,11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation_code = {} \n",
    "\n",
    "for key, value in codes.items():\n",
    "\n",
    "    interpolation_code[key] = value[0,:].reshape(-1,1).transpose()\n",
    "\n",
    "    for i in range(1,value.shape[0]):\n",
    "\n",
    "        diff = np.squeeze(value[i,:]) - np.squeeze(value[i-1,:])\n",
    "\n",
    "        interp_start = np.squeeze(interpolation_code[key][-1,:])\n",
    "\n",
    "        for j in range(1,11):\n",
    "\n",
    "            update = interp_start + diff*j*0.1\n",
    "\n",
    "            interpolation_code[key] = np.vstack((interpolation_code[key], update.reshape(-1,1).transpose()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/Users/dysprague/Ponce_rotation/data/images_perturbed_test'\n",
    "\n",
    "for key in codes.keys():\n",
    "    interp = interpolation_code[key]\n",
    "\n",
    "    for i in range(interp.shape[0]):\n",
    "\n",
    "        os.makedirs(os.path.join(save_dir, f'interp_{str(0.1)}', key), exist_ok=True)\n",
    "\n",
    "        interp_im = torch.tensor(interp[i,:]).float()\n",
    "        img_interp = G.visualize(interp_im.detach())\n",
    "        img_interp_save = ToPILImage()(np.squeeze(img_interp))\n",
    "        img_interp_save.save(os.path.join(save_dir, f'interp_{str(0.1)}', key, f\"frame_{i}_inverted.png\"))\n",
    "        np.save(os.path.join(save_dir, f'interp_{str(0.1)}', key, f\"frame_{i}_code.npy\"), arr=interp_im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in os.listdir(os.path.join(save_dir)):\n",
    "    if folder == '.DS_Store':\n",
    "        continue\n",
    "\n",
    "    for img_folder in os.listdir(os.path.join(save_dir,folder)):\n",
    "        if img_folder =='.DS_Store':\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(save_dir, folder, img_folder)\n",
    "        os.makedirs(os.path.join(save_dir, '..', 'videos_perturbed_test', folder), exist_ok=True)\n",
    "        video_name = os.path.join(save_dir, '..', 'videos_perturbed_test', folder, img_folder) + '.mp4'\n",
    "\n",
    "        frames = int(len(os.listdir(img_path))/2)\n",
    "\n",
    "        images = [f'frame_{i}_inverted.png' for i in range(frames)]\n",
    "\n",
    "        #images = [img for img in os.listdir(img_folder) if img.endswith(\"inverted.png\")]\n",
    "        frame = cv2.imread(os.path.join(img_path, images[0]))\n",
    "        height, width, layers = frame.shape\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "        if folder == 'interp_0.1':\n",
    "            video = cv2.VideoWriter(video_name, fourcc, len(images)/10, (width,height))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for image in images:\n",
    "            video.write(cv2.imread(os.path.join(img_path, image)))\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "        video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup images and videos for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/dysprague/Ponce_rotation/data'\n",
    "save_folder = '/Users/dysprague/Ponce_rotation/data/move_stimuli'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  4.,  8., 12., 16., 20., 24., 28., 32., 36., 40., 44., 48.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(50/4)*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for folder in os.listdir(os.path.join(data_dir, 'videos_inverted')):\n",
    "    if folder == '.DS_Store':\n",
    "        continue\n",
    "    img_folder = os.path.join(data_dir, 'videos_inverted', folder)\n",
    "    pert_folder = os.path.join(data_dir, 'images_perturbed_test/noise_0.5_original', folder)\n",
    "\n",
    "    img_dest = os.path.join(save_folder, 'images')\n",
    "    pert_dest = os.path.join(save_folder, 'images_perturbed')\n",
    "\n",
    "    frames = int(len(os.listdir(img_folder))/3)\n",
    "\n",
    "    images = [f'frame_{i}_original.png' for i in range(frames)]\n",
    "    images_pert = [f'frame_{i}_inverted.png' for i in range(frames)]\n",
    "\n",
    "    for i in range(len(images)):\n",
    "\n",
    "        shutil.copyfile(os.path.join(img_folder, images[i]), os.path.join(img_dest, f'{folder}_{str(i)}_original.png'))\n",
    "        shutil.copyfile(os.path.join(pert_folder, images_pert[i]), os.path.join(pert_dest, f'{folder}_{str(i)}_noise_0.5.png'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for folder in os.listdir(os.path.join(data_dir, 'videos_inverted')):\n",
    "    if folder == '.DS_Store':\n",
    "        continue\n",
    "    img_folder = os.path.join(data_dir, 'videos_inverted', folder)\n",
    "\n",
    "    img_sped_dest = os.path.join(save_folder, 'images_sped')\n",
    "    img_inv_sped_dest = os.path.join(save_folder, 'images_sped_inverted')\n",
    "    img_first_dest = os.path.join(save_folder, 'images_first')\n",
    "    img_inv_first_dest = os.path.join(save_folder, 'images_first_inverted')\n",
    " \n",
    "    frames = int(len(os.listdir(img_folder))/3)\n",
    "\n",
    "    compress = frames/12\n",
    "\n",
    "    frames_use_sped = (np.arange(int(frames/compress))*compress).astype('int')\n",
    "\n",
    "    if frames == 120:\n",
    "        frames_use_first = (np.arange(12)*3).astype('int')\n",
    "    elif frames ==60:\n",
    "        frames_use_first = (np.arange(12)*5/4).astype('int')\n",
    "    else:\n",
    "        frames_use_first = (np.arange(12)).astype('int')\n",
    "\n",
    "    images_sped = [f'frame_{i}_original.png' for i in frames_use_sped]\n",
    "    images_first = [f'frame_{i}_original.png' for i in frames_use_first]\n",
    "\n",
    "    images_sped_inv = [f'frame_{i}_inverted.png' for i in frames_use_sped]\n",
    "    images_first_inv = [f'frame_{i}_inverted.png' for i in frames_use_first]\n",
    "\n",
    "\n",
    "    for i, j in enumerate(frames_use_sped):\n",
    "\n",
    "        shutil.copyfile(os.path.join(img_folder, images_sped[i]), os.path.join(img_sped_dest, f'{folder}_{str(j)}_original.png'))\n",
    "        shutil.copyfile(os.path.join(img_folder, images_sped_inv[i]), os.path.join(img_inv_sped_dest, f'{folder}_{str(j)}_inverted.png'))\n",
    "        \n",
    "    for i, j in enumerate(frames_use_first):\n",
    "        shutil.copyfile(os.path.join(img_folder, images_first[i]), os.path.join(img_first_dest, f'{folder}_{str(j)}_original.png'))\n",
    "        shutil.copyfile(os.path.join(img_folder, images_first_inv[i]), os.path.join(img_inv_first_dest, f'{folder}_{str(j)}_inverted.png'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for folder in os.listdir(os.path.join(data_dir, 'videos_inverted')):\n",
    "    if folder == '.DS_Store':\n",
    "        continue\n",
    "    img_folder = os.path.join(data_dir, 'images_perturbed_test', 'noise_0.5_original', folder)\n",
    "\n",
    "    img_sped_dest = os.path.join(save_folder, 'images_perturbed_sped')\n",
    "    img_first_dest = os.path.join(save_folder, 'images_perturbed_first')\n",
    " \n",
    "    frames = int(len(os.listdir(img_folder))/2)\n",
    "\n",
    "    compress = frames/12\n",
    "\n",
    "    frames_use_sped = (np.arange(int(frames/compress))*compress).astype('int')\n",
    "\n",
    "    if frames == 120:\n",
    "        frames_use_first = (np.arange(12)*3).astype('int')\n",
    "    elif frames ==60:\n",
    "        frames_use_first = (np.arange(12)*5/4).astype('int')\n",
    "    else:\n",
    "        frames_use_first = (np.arange(12)).astype('int')\n",
    "\n",
    "    images_sped = [f'frame_{i}_inverted.png' for i in frames_use_sped]\n",
    "    images_first = [f'frame_{i}_inverted.png' for i in frames_use_first]\n",
    "\n",
    "    for i, j in enumerate(frames_use_sped):\n",
    "\n",
    "        shutil.copyfile(os.path.join(img_folder, images_sped[i]), os.path.join(img_sped_dest, f'{folder}_{str(j)}_noise.png'))\n",
    "\n",
    "    for i, j in enumerate(frames_use_first):\n",
    "\n",
    "        shutil.copyfile(os.path.join(img_folder, images_first[i]), os.path.join(img_first_dest, f'{folder}_{str(j)}_noise.png'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "for folder in os.listdir(os.path.join(data_dir, 'videos_inverted')):\n",
    "    if folder == '.DS_Store':\n",
    "        continue\n",
    "\n",
    "    for cond in ['inverted', 'noise', 'original']:\n",
    "\n",
    "        img_folder = os.path.join(data_dir, 'videos_inverted', folder)\n",
    "\n",
    "        img_sped_folder = os.path.join(save_folder, f'images_sped_{cond}')\n",
    "        img_first_folder = os.path.join(save_folder, f'images_first_{cond}')\n",
    "\n",
    "        sped_video_name = os.path.join(save_folder, f'movies_sped_{cond}',f'{folder}_sped_{cond}.mp4')\n",
    "        first_video_name = os.path.join(save_folder, f'movies_first_{cond}',f'{folder}_first_{cond}.mp4')\n",
    "        sped_shuffled_name = os.path.join(save_folder, f'movies_sped_{cond}_shuffle',f'{folder}_sped_{cond}_shuffle.mp4')\n",
    "        first_shuffled_name = os.path.join(save_folder, f'movies_first_{cond}_shuffle',f'{folder}_first_{cond}_shuffle.mp4')\n",
    "\n",
    "        frames = int(len(os.listdir(img_folder))/3)\n",
    "\n",
    "        compress = frames/12\n",
    "\n",
    "        frames_use_sped = (np.arange(int(frames/compress))*compress).astype('int')\n",
    "\n",
    "        if frames == 120:\n",
    "            frames_use_first = (np.arange(12)*3).astype('int')\n",
    "        elif frames ==60:\n",
    "            frames_use_first = (np.arange(12)*5/4).astype('int')\n",
    "        else:\n",
    "            frames_use_first = (np.arange(12)).astype('int')\n",
    "\n",
    "        images_sped = [f'{folder}_{i}_{cond}.png' for i in frames_use_sped]\n",
    "        images_first = [f'{folder}_{i}_{cond}.png' for i in frames_use_first]\n",
    "\n",
    "        images_sped_shuffled = [f'{folder}_{i}_{cond}.png' for i in frames_use_sped]\n",
    "        random.shuffle(images_sped_shuffled)\n",
    "\n",
    "        images_first_shuffled = [f'{folder}_{i}_{cond}.png' for i in frames_use_first]\n",
    "        random.shuffle(images_first_shuffled)\n",
    "\n",
    "        frame = cv2.imread(os.path.join(img_sped_folder, images_sped[0]))\n",
    "        height, width, layers = frame.shape\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        video_sped = cv2.VideoWriter(sped_video_name, fourcc, len(images_sped)*2, (width,height))\n",
    "\n",
    "        for image in images_sped:\n",
    "            video_sped.write(cv2.imread(os.path.join(img_sped_folder, image)))\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "        video_sped.release()\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        video_shuffled = cv2.VideoWriter(sped_shuffled_name, fourcc, len(images_sped)*2, (width,height))\n",
    "        \n",
    "        for image in images_sped_shuffled:\n",
    "            video_shuffled.write(cv2.imread(os.path.join(img_sped_folder, image)))\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "        video_shuffled.release()\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        video_first = cv2.VideoWriter(first_video_name, fourcc, len(images_first)*2, (width,height))\n",
    "\n",
    "        for image in images_first:\n",
    "            video_first.write(cv2.imread(os.path.join(img_first_folder, image)))\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "        video_first.release()\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        video_first_shuffled = cv2.VideoWriter(first_shuffled_name, fourcc, len(images_first)*2, (width,height))\n",
    "\n",
    "        for image in images_first_shuffled:\n",
    "            video_first_shuffled.write(cv2.imread(os.path.join(img_first_folder, image)))\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "        video_first_shuffled.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "for folder in os.listdir(os.path.join(data_dir, 'videos_inverted')):\n",
    "    if folder == '.DS_Store':\n",
    "        continue\n",
    "    img_folder = os.path.join(data_dir, 'videos_inverted', folder)\n",
    "    img_sped_folder = os.path.join(save_folder, 'images_perturbed_sped')\n",
    "    sped_video_name = os.path.join(save_folder, 'movies_perturbed_sped',f'{folder}_noise.mp4')\n",
    "    sped_shuffled_name = os.path.join(save_folder, 'movies_perturbed_shuffled_sped',f'{folder}_shuffled_noise.mp4')\n",
    "\n",
    "    frames = int(len(os.listdir(img_folder))/3)\n",
    "\n",
    "    compress = frames/12\n",
    "\n",
    "    frames_use_sped = np.arange(int(frames/compress))\n",
    "\n",
    "    images_sped = [f'{folder}_{i}_noise.png' for i in frames_use_sped]\n",
    "    images_shuffled = [f'{folder}_{i}_noise.png' for i in frames_use_sped]\n",
    "    random.shuffle(images_shuffled)\n",
    "\n",
    "    #images = [img for img in os.listdir(img_folder) if img.endswith(\"inverted.png\")]\n",
    "    frame = cv2.imread(os.path.join(img_sped_folder, images_sped[0]))\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_sped = cv2.VideoWriter(sped_video_name, fourcc, len(images_sped)*2, (width,height))\n",
    "\n",
    "    for image in images_sped:\n",
    "        video_sped.write(cv2.imread(os.path.join(img_sped_folder, image)))\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video_sped.release()\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_shuffled = cv2.VideoWriter(sped_shuffled_name, fourcc, len(images_sped)*2, (width,height))\n",
    "    \n",
    "    for image in images_shuffled:\n",
    "        video_shuffled.write(cv2.imread(os.path.join(img_sped_folder, image)))\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video_shuffled.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "for folder in os.listdir(os.path.join(data_dir, 'videos_inverted')):\n",
    "    if folder == '.DS_Store':\n",
    "        continue\n",
    "    img_folder = os.path.join(data_dir, 'videos_inverted', folder)\n",
    "    original_video_name = os.path.join(save_folder, 'movies_original',f'{folder}_original.mp4')\n",
    "    shuffled_video_name = os.path.join(save_folder, 'movies_shuffled',f'{folder}_shuffled.mp4')\n",
    "\n",
    "    frames = int(len(os.listdir(img_folder))/3)\n",
    "\n",
    "    images = [f'frame_{i}_original.png' for i in range(frames)]\n",
    "    img_shuffled = [f'frame_{i}_original.png' for i in range(frames)]\n",
    "    random.shuffle(img_shuffled)\n",
    "\n",
    "    #images = [img for img in os.listdir(img_folder) if img.endswith(\"inverted.png\")]\n",
    "    frame = cv2.imread(os.path.join(img_folder, images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_original = cv2.VideoWriter(original_video_name, fourcc, len(images)/2, (width,height))\n",
    "    \n",
    "\n",
    "    for image in images:\n",
    "        video_original.write(cv2.imread(os.path.join(img_folder, image)))\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video_original.release()\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_shuffled = cv2.VideoWriter(shuffled_video_name, fourcc, len(images)/2, (width,height))\n",
    "\n",
    "    for image in img_shuffled:\n",
    "        video_shuffled.write(cv2.imread(os.path.join(img_folder, image)))\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video_shuffled.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ponce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
